{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f07e31e",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c87af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the key concepts of the text delimited by triple backticks in simple terms ```Machine learning is a field of artificial intelligence that enables computers to learn form data and make predictions```\n"
     ]
    }
   ],
   "source": [
    "text = \"Machine learning is a field of artificial intelligence that enables computers to learn form data and make predictions\"\n",
    "prompt = f\"\"\"Explain the key concepts of the text delimited by triple backticks in simple terms ```{text}```\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33bbeaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.genai as genai\n",
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98fb23",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16fe41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api = os.getenv('api_key2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79400e19",
   "metadata": {},
   "source": [
    "### Zero-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e94bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Translate the followig English sentence into French: 'The weather is nice today.\"\n",
    "\n",
    "# client = genai.Client(api_key = api)\n",
    "# response = client.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad23303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"The weather is nice today\" into French is: \"Le temps est beau aujourd'hui.\"\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}], temperature=1)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae9385",
   "metadata": {},
   "source": [
    "### One-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfe6e8",
   "metadata": {},
   "source": [
    "There should only be one example since it is one-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b775f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"Detect the language of the following sentences:\n",
    "text: \"Good morning\" -> language: \"English\"\n",
    "text: \"A plus tard\" -> language: \"French\"\n",
    "Now detect:\n",
    "text: \"Gracias!\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b550fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: \"Spanish\"\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt2}], temperature=0)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e924f",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ea1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt3 = \"\"\"Determine the sentiment of the following sentences:\n",
    "text: \"I love this product! It works perfectly.\" -> Classification: Positive\n",
    "text: \"The servis was terrible. I'm very disappointed.\" -> Classification: Negative\n",
    "text: \"The food was okay, nothing special.\" -> Classification: Neutral\n",
    "Now analyze the following sentences\n",
    "\"The movie was amazing, I enjoyed every moment of it!\"\n",
    "\"The food is top-notch, but the customer service is trash\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9c4478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the sentiment classifications for the provided sentences:\n",
      "\n",
      "1. \"The movie was amazing, I enjoyed every moment of it!\" -> Classification: Positive\n",
      "2. \"The food is top-notch, but the customer service is trash\" -> Classification: Mixed (Positive for the food, Negative for the customer service) \n",
      "\n",
      "If you need a single classification for the second sentence, it could be considered Negative overall due to the stronger negative sentiment regarding customer service.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt3}], temperature=0)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819cee35",
   "metadata": {},
   "source": [
    "### Multi-step prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4890746",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Marie Curie discovered radium 1898\"\n",
    "\n",
    "prompt4 = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
    "Step1: Identify the key entities in the sentence.\n",
    "Step2: Classify each entity as a person, event, or object.\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df29a7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify the key entities in the sentence.\n",
      "- Marie Curie\n",
      "- radium\n",
      "- 1898\n",
      "\n",
      "Step 2: Classify each entity as a person, event, or object.\n",
      "- Marie Curie: Person\n",
      "- radium: Object\n",
      "- 1898: Event (specifically, a year indicating the time of the discovery)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt4}], temperature=0)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac600c2f",
   "metadata": {},
   "source": [
    "### Chain-of-thought prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d81409ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt5 = \"John has 3 apples. He buyd 5 more and gives 2 away. How many apples does he have now? Think step by step\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f927d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step by step:\n",
      "\n",
      "1. **Initial number of apples**: John starts with 3 apples.\n",
      "2. **Apples bought**: He buys 5 more apples. \n",
      "   - So, 3 (initial apples) + 5 (bought apples) = 8 apples.\n",
      "3. **Apples given away**: He gives away 2 apples.\n",
      "   - So, 8 (current apples) - 2 (given away) = 6 apples.\n",
      "\n",
      "Therefore, John has **6 apples** now.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt5}], temperature=0)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89d307",
   "metadata": {},
   "source": [
    "### Self-Consistency Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d0b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Imagine three completely independent experts who reason differently are answering this question. Final answer is obtained by majority vote. The question is: \"\n",
    "question = \"A bookstore has 20 books on a shelf. A customer buys 5 books. Then, the store restocks with double the number of books bought. After that, another customer buys 8 books. How many books are left on the shelf?\"\n",
    "prompt6 = instruction+question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4eeed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the problem step by step.\n",
      "\n",
      "1. **Initial number of books**: The bookstore starts with 20 books.\n",
      "2. **First customer buys 5 books**: \n",
      "   - Books left after the first purchase = 20 - 5 = 15 books.\n",
      "3. **Store restocks with double the number of books bought**: \n",
      "   - The store restocks with 2 * 5 = 10 books.\n",
      "   - Total books after restocking = 15 + 10 = 25 books.\n",
      "4. **Second customer buys 8 books**: \n",
      "   - Books left after the second purchase = 25 - 8 = 17 books.\n",
      "\n",
      "So, the final answer is that there are **17 books left on the shelf**. \n",
      "\n",
      "Now, let's consider the three independent experts:\n",
      "\n",
      "- **Expert 1**: Follows the steps logically and concludes there are 17 books left.\n",
      "- **Expert 2**: Makes a mistake in the restocking step and thinks there are 20 books left after the first purchase, then adds 10, leading to 30 books, and after the second purchase, concludes there are 22 books left.\n",
      "- **Expert 3**: Miscalculates the number of books after the first purchase and thinks there are 15 books left, then adds 10, leading to 25 books, and after the second purchase, concludes there are 17 books left.\n",
      "\n",
      "Now, we tally the votes:\n",
      "- Expert 1: 17 books\n",
      "- Expert 2: 22 books\n",
      "- Expert 3: 17 books\n",
      "\n",
      "The majority vote is for **17 books**. \n",
      "\n",
      "Thus, the final answer is **17 books left on the shelf**.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt6}], temperature=0)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed6625",
   "metadata": {},
   "source": [
    "### Role-playing prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873bf963",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Act as an experience hiring manager. Ask me five interview questions one by one. After I respond, provide constructive feedback on m answer, includeing strengths and areas for improvement. If my respnse is incomplete, guide me toward a better answer.\"\n",
    "\n",
    "user_prompt = \"I'm preparing for a Data Scientist interview. Can you ask me five questions and evaluate my response?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e0eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! Let's get started with the first question.\n",
      "\n",
      "**Question 1:** Can you explain the difference between supervised and unsupervised learning? Please provide examples of each.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "{\"role\": \"user\", \"content\": user_prompt}], temperature=0)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419cc79",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e82524",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "ipa = os.getenv('api_key1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22fef7",
   "metadata": {},
   "source": [
    "### Zero shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d9c83fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and natural way to say \"The weather is nice today\" in French is:\n",
      "\n",
      "**Il fait beau aujourd'hui.**\n",
      "\n",
      "*   **Il fait beau** is the standard expression for \"the weather is nice/beautiful.\" (Literally \"It makes beautiful.\")\n",
      "*   **aujourd'hui** means \"today.\"\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = ipa)\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents= prompt\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc725c3",
   "metadata": {},
   "source": [
    "### Two-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044e9765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \"Gracias!\" -> language: \"Spanish\"\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = ipa)\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents= prompt2\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3cc36",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d645c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The movie was amazing, I enjoyed every moment of it!\" -> Classification: Positive\n",
      "\"The food is top-notch, but the customer service is trash\" -> Classification: Negative\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = ipa)\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents= prompt3\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fec0de",
   "metadata": {},
   "source": [
    "### Multi-step Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf3b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Step1: Identify the key entities in the sentence.**\n",
      "*   Marie Curie\n",
      "*   radium\n",
      "*   discovered radium 1898 (representing the action/occurrence)\n",
      "\n",
      "**Step2: Classify each entity as a person, event, or object.**\n",
      "*   **Marie Curie:** Person\n",
      "*   **radium:** Object\n",
      "*   **discovered radium 1898:** Event\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = ipa)\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents= prompt4\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb29f2",
   "metadata": {},
   "source": [
    "### Chain-of-thought prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0600574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step by step:\n",
      "\n",
      "1.  **John starts with:** 3 apples\n",
      "2.  **He buys 5 more:** 3 + 5 = 8 apples\n",
      "3.  **He gives 2 away:** 8 - 2 = 6 apples\n",
      "\n",
      "John has **6** apples now.\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = ipa)\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents= prompt5\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00eade6",
   "metadata": {},
   "source": [
    "### Self-consistency Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd3d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's track the number of books step-by-step:\n",
      "\n",
      "1.  **Initial state:** The shelf has 20 books.\n",
      "2.  **First purchase:** A customer buys 5 books.\n",
      "    *   Books remaining = 20 - 5 = 15 books.\n",
      "3.  **Restocking:** The store restocks with double the number of books bought (double of 5 is 10 books).\n",
      "    *   Books on shelf = 15 + 10 = 25 books.\n",
      "4.  **Second purchase:** Another customer buys 8 books.\n",
      "    *   Books remaining = 25 - 8 = 17 books.\n",
      "\n",
      "All three independent experts, reasoning logically, would arrive at the same sequence of calculations. Therefore, by majority vote (which would be unanimous in this case):\n",
      "\n",
      "There are **17** books left on the shelf.\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key = ipa)\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents= prompt6\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b952f",
   "metadata": {},
   "source": [
    "### Role-playing Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = genai.Client(api_key = ipa)\n",
    "# response = client.models.generate_content(\n",
    "#     model = \"gemini-2.5-flash\",\n",
    "#     contents= system_prompt, user_prompt\n",
    "# )\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c76354f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent! Let's dive right in. As an experienced hiring manager, I'm keen to understand your practical experience and problem-solving approach.\n",
      "\n",
      "Here's your first question:\n",
      "\n",
      "**Question 1:** \"Tell me about a data science project you're particularly proud of. What was the problem you were trying to solve, what was your approach, and what was the impact?\"\n",
      "User is Speaking \n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key= ipa)\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config= genai.types.GenerateContentConfig(\n",
    "        system_instruction = system_prompt,\n",
    "        temperature=0.\n",
    "    )\n",
    ")\n",
    "response = chat.send_message(user_prompt)\n",
    "print(response.text)\n",
    "while True:\n",
    "    print(f\"User is Speaking \\n\")\n",
    "    user_input = input(\"\\nYou: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        response = chat.send_message(user_input)\n",
    "        print(f\"Gemini is Speaking: \\n{response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c56dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a birthday message for Timi, who is turning 4.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e12f0f",
   "metadata": {},
   "source": [
    "## Python f-strings and JSON Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e66707",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37fbbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a birthday message for Timi, who is turning 4.\n"
     ]
    }
   ],
   "source": [
    "name = \"Timi\"\n",
    "age = 4\n",
    "prompt = f\"Write a birthday message for {name}, who is turning {age}.\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1987e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birthday Message from AI: \n",
      " ğŸ‰ğŸˆ Happy 4th Birthday, Timi! ğŸˆğŸ‰\n",
      "\n",
      "Today is a super special day because youâ€™re turning 4! ğŸŒŸ Youâ€™re growing up so fast and bringing so much joy to everyone around you. May your day be filled with fun, laughter, and all your favorite thingsâ€”like cake, balloons, and maybe even some magical adventures! ğŸ‚ğŸˆâœ¨\n",
      "\n",
      "Keep shining bright and exploring the world with your big imagination. We canâ€™t wait to see all the amazing things youâ€™ll do this year! Have the best birthday ever, little superstar! ğŸŒˆğŸ’–\n",
      "\n",
      "Lots of love and big birthday hugs! ğŸ¥³ğŸ\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a friendly and creative assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "message = response.choices[0].message.content\n",
    "print(\"Birthday Message from AI: \\n\", message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928bc85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John', 'age': 16, 'interest': 'coding'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Working with JSON\n",
    "\n",
    "{\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 16,\n",
    "    \"interest\": \"coding\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:\n",
      " My name is Zara. I love coding and want to learn AI. Write a friendly and short guide on how I can start.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using JSON with prompt. This is useful for personalized projects\n",
    "import json\n",
    "\n",
    "user_profile = {\n",
    "    \"name\": \"Zara\",\n",
    "    \"interest\": \"coding\",\n",
    "    \"goal\": \"learn AI\",\n",
    "    \"tone\": \"friendly\",\n",
    "    \"length\": \"short\"\n",
    "}\n",
    "\n",
    "prompt = f\"\"\"My name is {user_profile['name']}. I love {user_profile['interest']} and want to {user_profile['goal']}. Write a {user_profile['tone']} and {user_profile['length']} guide on how I can start.\n",
    "\"\"\"\n",
    "print(\"Generated Prompt:\\n\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042c74f",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51eaad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Zara! Itâ€™s great to hear that youâ€™re interested in coding and want to dive into AI. Hereâ€™s a friendly guide to help you get started on your AI journey:\n",
      "\n",
      "### Step 1: Strengthen Your Coding Skills\n",
      "- **Languages to Learn**: Python is the most popular language for AI. If youâ€™re not familiar with it yet, start with Python basics.\n",
      "- **Resources**: Use platforms like Codecademy, freeCodeCamp, or Coursera to learn Python.\n",
      "\n",
      "### Step 2: Understand the Basics of AI\n",
      "- **Concepts to Explore**: Familiarize yourself with key AI concepts like machine learning, neural networks, and natural language processing.\n",
      "- **Online Courses**: Consider taking introductory courses on platforms like Coursera (e.g., Andrew Ngâ€™s Machine Learning course) or edX.\n",
      "\n",
      "### Step 3: Get Hands-On with Projects\n",
      "- **Start Small**: Build simple projects like a chatbot, a recommendation system, or a basic image classifier.\n",
      "- **Kaggle**: Join Kaggle to find datasets and participate in competitions. Itâ€™s a great way to practice and learn from others.\n",
      "\n",
      "### Step 4: Learn About Libraries and Frameworks\n",
      "- **Key Libraries**: Get comfortable with libraries like NumPy, Pandas, Matplotlib, and Scikit-learn for data manipulation and analysis.\n",
      "- **Deep Learning Frameworks**: Explore TensorFlow or PyTorch for building neural networks.\n",
      "\n",
      "### Step 5: Join the Community\n",
      "- **Forums and Groups**: Engage with communities on platforms like Reddit (r/MachineLearning), Stack Overflow, or join local meetups.\n",
      "- **Follow AI Blogs and Podcasts**: Stay updated with the latest trends and research in AI.\n",
      "\n",
      "### Step 6: Keep Learning and Experimenting\n",
      "- **Advanced Topics**: Once youâ€™re comfortable, explore advanced topics like reinforcement learning, computer vision, or generative models.\n",
      "- **Continuous Practice**: Keep building projects, contributing to open-source, and experimenting with new ideas.\n",
      "\n",
      "### Step 7: Build a Portfolio\n",
      "- **Showcase Your Work**: Create a GitHub repository to showcase your projects. This will be helpful for future job opportunities or collaborations.\n",
      "\n",
      "### Bonus Tips:\n",
      "- **Stay Curious**: AI is a rapidly evolving field, so keep learning and exploring new technologies.\n",
      "- **Have Fun**: Enjoy the process! Experimenting and building things is one of the best parts of learning AI.\n",
      "\n",
      "Good luck on your AI journey, Zara! Youâ€™ve got this! ğŸŒŸ\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "reply = response.choices[0].message.content\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Practical Application of Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5346eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the GTA Online street fight based on the provided exchange:\n",
      "\n",
      "1. **Who started it?**\n",
      "   - The conflict appears to have been initiated by **@ThugLife99**, who blew up @LS_King's car. @LS_King's message indicates that he is responding to an action that was taken against him, suggesting that he is the victim in this scenario.\n",
      "\n",
      "2. **Most toxic word?**\n",
      "   - The most toxic word in this exchange is likely **\"Cry\"**. It implies that @ThugLife99 is dismissing @LS_King's feelings and encouraging him to complain rather than addressing the situation maturely. The hashtag **#GetRekt** also adds to the toxicity by mocking @LS_King's predicament.\n",
      "\n",
      "3. **Suggested peace treaty (funny):**\n",
      "   - \"How about we settle this like true gamers? Loser buys the winner a virtual snack from the in-game vending machine and promises to never blow up each other's cars again... unless it's a really bad parking job!\" \n",
      "\n",
      "This humorous peace treaty acknowledges the absurdity of the situation while promoting a lighthearted resolution.\n"
     ]
    }
   ],
   "source": [
    "# Social Media Drama\n",
    "\n",
    "text = \"\"\"@LS_King: Yo why'd you blow up my car? @ThugLife99: Cry about it #GetRekt\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Analyze this GTA Online street fight:\n",
    "1. Who started it?\n",
    "2. Most toxic word?\n",
    "3. Suggested peace treaty (funny):\n",
    "```{text}```\n",
    "\"\"\"\n",
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80cccca",
   "metadata": {},
   "source": [
    "## Structured Outpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "607b6b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information presented in a table format with thick straight horizontal and vertical lines:\n",
      "\n",
      "```\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚  Company   â”‚        Industry       â”‚        Stock Performance       â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚   Tesla    â”‚ Electric Vehicles     â”‚ Increased by 20% in the last  â”‚\n",
      "â”‚            â”‚                       â”‚ year                          â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚   Apple    â”‚ Technology           â”‚ Increased by 15% in the last  â”‚\n",
      "â”‚            â”‚                       â”‚ year                          â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  Amazon    â”‚ E-commerce & Cloud   â”‚ Increased by 10% in the last  â”‚\n",
      "â”‚            â”‚ Computing            â”‚ year                          â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "```\n",
      "\n",
      "This table organizes the information clearly into the specified columns.\n"
     ]
    }
   ],
   "source": [
    "text = \"Tesla is an electric vehicle company. Its stock price has increase by 20% in the last year.  Apple is a technology company known for its iphones. Its stock price has increased by 15% in the last year. Amazon is an e-commerce and cloud computing giant. Its stock price has increased by 10% in the last year.\"\n",
    "\n",
    "prompt = f\"\"\"Convert the following information into a table format with columns for company, industry, and stock performance. With thick straight horizontal and vertical lines both for the rows and columns:\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1eb5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Key Industries AI is Transforming:\n",
      "  - Healthcare\n",
      "  - Finance\n",
      "  - Education\n",
      "\n",
      "- Impact of AI:\n",
      "  - Improves efficiency\n",
      "  - Enhances decision making\n"
     ]
    }
   ],
   "source": [
    "# List\n",
    "\n",
    "text = \"Artificial Intelligence is transforming industries like healthcare, finance, and education by improving efficiency and decision making.\"\n",
    "\n",
    "prompt = f\"\"\"Format the response in a list:\n",
    "- Summarize the key industries AI is transforming.\n",
    "- Highlight its impact.\n",
    "\n",
    "Text: ```{text}```\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78520627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"profession\": \"data scientist\",\n",
      "  \"skills\": [\"python\", \"data learning\", \"machine learning\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# JSON. this format is used for large scale projects\n",
    "\n",
    "text = \"John is a data scientist with expertise in python, data learning, and machine learning.\"\n",
    "prompt = f\"\"\"Extract key details from the text and return the output in JSON format.\n",
    "Text: ```{text}```\n",
    "Output format:\n",
    "{{\"name\": \",\n",
    "\"profession\": \",\n",
    "\"skills\": []}}\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1543694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The Impact of a Balanced Diet on Physical and Mental Health\n",
      "\n",
      "## Introduction\n",
      "A balanced diet is essential for maintaining overall health and well-being. It provides the necessary nutrients that the body and mind require to function optimally.\n",
      "\n",
      "## Physical Health Benefits\n",
      "A balanced diet, rich in fruits, vegetables, whole grains, lean proteins, and healthy fats, plays a crucial role in physical health. It helps in maintaining a healthy weight, reducing the risk of chronic diseases such as heart disease, diabetes, and obesity. Nutrients like vitamins and minerals support immune function, promote healthy skin, and enhance energy levels, enabling individuals to engage in physical activities more effectively.\n",
      "\n",
      "## Mental Health Benefits\n",
      "In addition to physical health, a balanced diet significantly impacts mental health. Nutrient-dense foods contribute to improved mood and cognitive function. For instance, omega-3 fatty acids found in fish are linked to lower rates of depression, while antioxidants in fruits and vegetables can protect against cognitive decline. Furthermore, a stable blood sugar level, achieved through a balanced intake of carbohydrates, can help regulate mood swings and reduce anxiety.\n",
      "\n",
      "## Conclusion\n",
      "In summary, a balanced diet is fundamental to both physical and mental health. By providing essential nutrients, it supports bodily functions and enhances emotional well-being, ultimately leading to a higher quality of life. Prioritizing a balanced diet can yield long-term health benefits, making it a vital component of a healthy lifestyle.\n"
     ]
    }
   ],
   "source": [
    "# Structured Paragraph\n",
    "# Can be used for automated social media posts\n",
    "prompt = \"Write a structured paragraph with clear headings and subheadings about the impact of a balanced diet on physical and mental health\"\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c92a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Text: In a distant kingdom, a brave knight named Arthur set out on a quest to find the legendary sword of light. Through treacherous mountains and dark forests, he faced numerous challenges but remained determined to fulfill his destiny.\n",
      "- Summary: A brave knight named Arthur embarks on a quest to find the legendary sword of light, overcoming challenges in treacherous landscapes.\n"
     ]
    }
   ],
   "source": [
    "# Custom Output\n",
    "text = \"In a distant kingdom, a brave knight named Arthur set out on a quest to find the legendarty sword of light. Through treacherous mountains and dark forests, he faced numerous challenges but remained determined to fulfill his destiny.\"\n",
    "\n",
    "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
    "- If the text is short (around 20 words or fewer), generate a suitable **Title**.\n",
    "- If the text is longer than 20 words, generate a concise **Summary**.\n",
    "\n",
    "Use the following format for the output:\n",
    "- Text: <provided text>\n",
    "- Title/Summary: <generated content>\n",
    "\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(api_key=api)\n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages = [{\"role\": \"user\", \"content\": prompt }], temperature=0)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_Deep (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
