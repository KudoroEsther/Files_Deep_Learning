{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ced37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n",
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing libraries...\")\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import logging\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Libraries imported!\")\n",
    "\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21376593",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"C:\\Users\\owner\\Desktop\\Files_Deep_Learning\\NeuraGuide\\AI_Tools.csv\"\n",
    "\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "\n",
    "df = load_data(url)\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ce8ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tool Name', 'Category', 'Primary Function', 'Description', 'Website',\n",
       "       'Pricing Model', 'Key Features', 'Target Users', 'Launch Year',\n",
       "       'Company', 'category_rank', 'ID', 'Category_code', 'average_rating',\n",
       "       'review_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f032e5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinetix</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D animation with AI, democratiz...</td>\n",
       "      <td>https://www.kinetix.tech</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D modeling with AI-powered, tex...</td>\n",
       "      <td>https://nv-tlabs.github.io</td>\n",
       "      <td>Free</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize animation with AI-driven motion ...</td>\n",
       "      <td>https://www.deepmotion.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize VFX: automate animation, lightin...</td>\n",
       "      <td>https://wonderdynamics.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tool Name Category Primary Function  \\\n",
       "0           Kaedim       3D               3D   \n",
       "1          Kinetix       3D               3D   \n",
       "2  GET3D by NVIDIA       3D               3D   \n",
       "3       DeepMotion       3D               3D   \n",
       "4    Wonder Studio       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "1  Revolutionize 3D animation with AI, democratiz...   \n",
       "2  Revolutionize 3D modeling with AI-powered, tex...   \n",
       "3  Revolutionize animation with AI-driven motion ...   \n",
       "4  Revolutionize VFX: automate animation, lightin...   \n",
       "\n",
       "                      Website Pricing Model Key Features Target Users  \\\n",
       "0    https://www.kaedim3d.com          Paid  See website      General   \n",
       "1    https://www.kinetix.tech          Paid  See website      General   \n",
       "2  https://nv-tlabs.github.io          Free  See website      General   \n",
       "3  https://www.deepmotion.com      Freemium  See website      General   \n",
       "4  https://wonderdynamics.com      Freemium  See website      General   \n",
       "\n",
       "  Launch Year  Company  category_rank  ID  Category_code  average_rating  \\\n",
       "0     Unknown  Unknown              1   1              0            0.00   \n",
       "1     Unknown  Unknown              2   2              0            0.00   \n",
       "2     Unknown  Unknown              3   3              0            0.00   \n",
       "3     Unknown  Unknown              4   4              0            0.00   \n",
       "4     Unknown  Unknown              5   5              0            0.00   \n",
       "\n",
       "   review_count  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefed848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54910, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16834a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Year    1420\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3efc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Launch Year\"] = np.where(df[\"Launch Year\"] == \"Unknown\", \n",
    "                             np.random.randint(2020, 2025, size=len(df)), \n",
    "                             df[\"Launch Year\"]) \n",
    "\n",
    "# df['Launch Year'] = df['Launch Year'].astype('Int64')\n",
    "\n",
    "df[\"average_rating\"] = np.where(df[\"average_rating\"] == 0.0, \n",
    "                             np.round(1 + 4 * np.random.beta(a=5, b=1.5, size=len(df)), 2), \n",
    "                             df[\"average_rating\"]) \n",
    "\n",
    "mask = df[\"Company\"] == \"Unknown\"\n",
    "df.loc[mask, \"Company\"] = df.loc[mask, \"Tool Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e6dfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2022</td>\n",
       "      <td>Kaedim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tool Name Category Primary Function  \\\n",
       "0    Kaedim       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "\n",
       "                    Website Pricing Model Key Features Target Users  \\\n",
       "0  https://www.kaedim3d.com          Paid  See website      General   \n",
       "\n",
       "  Launch Year Company  category_rank  ID  Category_code  average_rating  \\\n",
       "0        2022  Kaedim              1   1              0            4.26   \n",
       "\n",
       "   review_count  \n",
       "0             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13773ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54910 entries, 0 to 54909\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Tool Name         54910 non-null  object \n",
      " 1   Category          54910 non-null  object \n",
      " 2   Primary Function  54910 non-null  object \n",
      " 3   Description       54910 non-null  object \n",
      " 4   Website           54910 non-null  object \n",
      " 5   Pricing Model     54910 non-null  object \n",
      " 6   Key Features      54910 non-null  object \n",
      " 7   Target Users      54910 non-null  object \n",
      " 8   Launch Year       53490 non-null  object \n",
      " 9   Company           54910 non-null  object \n",
      " 10  category_rank     54910 non-null  int64  \n",
      " 11  ID                54910 non-null  int64  \n",
      " 12  Category_code     54910 non-null  int64  \n",
      " 13  average_rating    54910 non-null  float64\n",
      " 14  review_count      54910 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(10)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aebe5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Year    1420\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53239363",
   "metadata": {},
   "source": [
    "## Identify and Remove Duplicate Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d7b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicates\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(df):\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"Duplicated rows: {duplicates}\")\n",
    "        # df = df.drop_duplicates(inplace=True)\n",
    "        # dropped = df.duplicated().sum()\n",
    "        # print(f\"\\nDuplicates: {dropped}\")\n",
    "    else:\n",
    "        print(\"There are no duplicates\")\n",
    "\n",
    "check_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf527bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:33:12,369 - INFO - DuplicateHandler initialized with 54910 records\n",
      "2026-02-12 23:33:12,371 - INFO - Duplicate detection keys: Tool Name, Company, Website\n",
      "2026-02-12 23:33:12,629 - INFO - Found 0 duplicate records in 0 groups\n",
      "2026-02-12 23:33:12,635 - INFO - No duplicates found\n"
     ]
    }
   ],
   "source": [
    "# Detect duplicate entries using Tool Name, Company, and Website. Decide which record to keep and remove the rest using deterministic logic.\n",
    "\n",
    "class DuplicateHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.duplicate_keys = ['Tool Name', 'Company', 'Website']\n",
    "        logger.info(f\"DuplicateHandler initialized with {len(self.df)} records\")\n",
    "        logger.info(f\"Duplicate detection keys: {', '.join(self.duplicate_keys)}\")\n",
    "        \n",
    "    def find_duplicates(self):\n",
    "        \"\"\"Identify duplicate groups\"\"\"\n",
    "        duplicates = self.df[self.df.duplicated(subset=self.duplicate_keys, keep=False)]\n",
    "        logger.info(f\"Found {len(duplicates)} duplicate records in {duplicates.groupby(self.duplicate_keys, dropna=False).ngroups} groups\")\n",
    "        return duplicates\n",
    "    \n",
    "    def rank_records(self, group):\n",
    "        \"\"\"Score records: higher is better\"\"\"\n",
    "        scores = pd.DataFrame(index=group.index)\n",
    "        scores['completeness'] = group.notna().sum(axis=1)\n",
    "        scores['reviews'] = group['review_count'].fillna(0)\n",
    "        scores['rating'] = group['average_rating'].fillna(0)\n",
    "        scores['recency'] = group['Launch Year'].fillna(0)\n",
    "        scores['position'] = -np.arange(len(group))  # negative for ascending\n",
    "        return scores.sum(axis=1).idxmax()\n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Keep best record per duplicate group\"\"\"\n",
    "        dupes = self.find_duplicates()\n",
    "        if dupes.empty:\n",
    "            logger.info(\"No duplicates found\")\n",
    "            return self.df, pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "            keep_indices = dupes.groupby(self.duplicate_keys, dropna=False).apply(self.rank_records)\n",
    "            removed = self.df[self.df.index.isin(dupes.index) & ~self.df.index.isin(keep_indices)]\n",
    "            cleaned = self.df[~self.df.index.isin(dupes.index) | self.df.index.isin(keep_indices)]\n",
    "            \n",
    "            logger.info(f\"Removed {len(removed)} duplicate records\")\n",
    "            logger.info(f\"Retained {len(cleaned)} unique records\")\n",
    "            return cleaned.reset_index(drop=True), removed\n",
    "\n",
    "# Usage:\n",
    "handler = DuplicateHandler(df)\n",
    "cleaned_df, removed_records = handler.remove_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b667c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54910, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f4c4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cleaned_df[\"Launch Year\"] = np.where(cleaned_df[\"Launch Year\"] == \"Unknown\", \n",
    "#                              np.random.randint(2020, 2025, size=len(cleaned_df)), \n",
    "#                              cleaned_df[\"Launch Year\"]) \n",
    "\n",
    "# cleaned_df[\"average_rating\"] = np.where(cleaned_df[\"average_rating\"] == 0.0, \n",
    "#                              np.round(1 + 4 * np.random.beta(a=5, b=1.5, size=len(cleaned_df)), 2), \n",
    "#                              cleaned_df[\"average_rating\"]) \n",
    "\n",
    "# mask = cleaned_df[\"Company\"] == \"Unknown\"\n",
    "# cleaned_df.loc[mask, \"Company\"] = cleaned_df.loc[mask, \"Tool Name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b8736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Year    1420\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f48ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2022</td>\n",
       "      <td>Kaedim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinetix</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D animation with AI, democratiz...</td>\n",
       "      <td>https://www.kinetix.tech</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>Kinetix</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D modeling with AI-powered, tex...</td>\n",
       "      <td>https://nv-tlabs.github.io</td>\n",
       "      <td>Free</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize animation with AI-driven motion ...</td>\n",
       "      <td>https://www.deepmotion.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize VFX: automate animation, lightin...</td>\n",
       "      <td>https://wonderdynamics.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tool Name Category Primary Function  \\\n",
       "0           Kaedim       3D               3D   \n",
       "1          Kinetix       3D               3D   \n",
       "2  GET3D by NVIDIA       3D               3D   \n",
       "3       DeepMotion       3D               3D   \n",
       "4    Wonder Studio       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "1  Revolutionize 3D animation with AI, democratiz...   \n",
       "2  Revolutionize 3D modeling with AI-powered, tex...   \n",
       "3  Revolutionize animation with AI-driven motion ...   \n",
       "4  Revolutionize VFX: automate animation, lightin...   \n",
       "\n",
       "                      Website Pricing Model Key Features Target Users  \\\n",
       "0    https://www.kaedim3d.com          Paid  See website      General   \n",
       "1    https://www.kinetix.tech          Paid  See website      General   \n",
       "2  https://nv-tlabs.github.io          Free  See website      General   \n",
       "3  https://www.deepmotion.com      Freemium  See website      General   \n",
       "4  https://wonderdynamics.com      Freemium  See website      General   \n",
       "\n",
       "  Launch Year          Company  category_rank  ID  Category_code  \\\n",
       "0        2022           Kaedim              1   1              0   \n",
       "1        2024          Kinetix              2   2              0   \n",
       "2        2024  GET3D by NVIDIA              3   3              0   \n",
       "3        2024       DeepMotion              4   4              0   \n",
       "4        2024    Wonder Studio              5   5              0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0            4.26             0  \n",
       "1            3.71             0  \n",
       "2            3.63             0  \n",
       "3            3.60             0  \n",
       "4            4.26             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dac611",
   "metadata": {},
   "source": [
    "## Identify rows missing essential information such as Tool Name, Category, or Website. Flag or remove records based on defined rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e12e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             missing_count  missing_pct\n",
      "Launch Year           1420         2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:33:13,609 - INFO - Flagged 1420 records with missing values\n",
      "2026-02-12 23:33:13,770 - INFO - Removed 1420 rows with missing values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MissingDataHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        # self.required_fields = required_fields or ['Tool Name', 'Category', 'Website']\n",
    "        \n",
    "    def find_missing(self):\n",
    "        \"\"\"Find rows with missing required fields\"\"\"\n",
    "        mask = self.df.isna().any(axis=1)\n",
    "        return self.df[mask]\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get missing data summary\"\"\"\n",
    "        summary = pd.DataFrame({\n",
    "            'missing_count': self.df.isna().sum(),\n",
    "            'missing_pct': (self.df.isna().sum() / len(self.df) * 100).round(2)\n",
    "        })\n",
    "        return summary[summary['missing_count'] > 0].sort_values('missing_count', ascending=False)\n",
    "    \n",
    "    def flag_records(self):\n",
    "        \"\"\"Add flag column for rows with missing data\"\"\"\n",
    "        flagged = self.df.copy()\n",
    "        flagged['has_missing'] = self.df.isna().any(axis=1)\n",
    "        logger.info(f\"Flagged {flagged['has_missing'].sum()} records with missing values\")\n",
    "        return flagged\n",
    "    \n",
    "    def remove_records(self):\n",
    "        \"\"\"Remove rows with missing required fields\"\"\"\n",
    "        missing = self.find_missing()\n",
    "        cleaned = self.df[~self.df.index.isin(missing.index)]\n",
    "        logger.info(f\"Removed {len(missing)} rows with missing values\")\n",
    "        return cleaned.reset_index(drop=True), missing\n",
    "\n",
    "# Usage:\n",
    "handler = MissingDataHandler(cleaned_df)\n",
    "print(handler.get_summary())\n",
    "flagged_df = handler.flag_records()\n",
    "# # or\n",
    "cleaned_df, removed = handler.remove_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6825227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeae8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['Launch Year'] = pd.to_numeric(cleaned_df['Launch Year'], errors='coerce').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afd80e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd695cc",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a18828",
   "metadata": {},
   "source": [
    "## Validate Website: URL format Dead / malformed links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63bd8f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:33:14,194 - INFO - URLValidator initialized for column: Website\n",
      "2026-02-12 23:33:14,200 - INFO - Total records to validate: 53490\n",
      "2026-02-12 23:33:20,056 - INFO - URL validation complete:\n",
      "2026-02-12 23:33:20,058 - INFO -   - Valid URLs: 53489\n",
      "2026-02-12 23:33:20,063 - INFO -   - Missing URLs: 0\n",
      "2026-02-12 23:33:20,065 - INFO -   - Invalid URLs: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URLs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:33:23,547 - INFO - URL validation complete:\n",
      "2026-02-12 23:33:23,548 - INFO -   - Valid URLs: 53489\n",
      "2026-02-12 23:33:23,549 - INFO -   - Missing URLs: 0\n",
      "2026-02-12 23:33:23,551 - INFO -   - Invalid URLs: 1\n",
      "2026-02-12 23:33:23,570 - INFO - Removed 1 records with invalid URLs\n",
      "2026-02-12 23:33:23,571 - INFO - Retained 53489 records with valid or missing URLs\n"
     ]
    }
   ],
   "source": [
    "class URLValidator:\n",
    "    def __init__(self, df, url_column='Website'):\n",
    "        self.df = df.copy()\n",
    "        self.url_column = url_column\n",
    "        logger.info(f\"URLValidator initialized for column: {url_column}\")\n",
    "        logger.info(f\"Total records to validate: {len(self.df)}\")\n",
    "        \n",
    "    def is_valid_url(self, url):\n",
    "        \"\"\"Check if URL is properly formatted\"\"\"\n",
    "        if pd.isna(url) or not isinstance(url, str):\n",
    "            return False\n",
    "        \n",
    "        # Basic pattern check\n",
    "        url = url.strip()\n",
    "        if not re.match(r'^https?://', url, re.IGNORECASE):\n",
    "            url = 'http://' + url\n",
    "        \n",
    "        try:\n",
    "            import validators\n",
    "            return validators.url(url) is True\n",
    "        except ImportError:\n",
    "            # Fallback to regex if validators not installed\n",
    "            pattern = re.compile(\n",
    "                r'^https?://'\n",
    "                r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}\\.?|'\n",
    "                r'localhost|'\n",
    "                r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'\n",
    "                r'(?::\\d+)?'\n",
    "                r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "            return bool(pattern.match(url))\n",
    "    \n",
    "    def validate_urls(self):\n",
    "        \"\"\"Validate all URLs and return results\"\"\"\n",
    "        results = self.df.copy()\n",
    "        results['url_valid'] = results[self.url_column].apply(self.is_valid_url)\n",
    "        results['url_missing'] = results[self.url_column].isna()\n",
    "\n",
    "        valid_count = results['url_valid'].sum()\n",
    "        missing_count = results['url_missing'].sum()\n",
    "        invalid_count = (~results['url_valid'] & ~results['url_missing']).sum()\n",
    "\n",
    "        logger.info(f\"URL validation complete:\")\n",
    "        logger.info(f\"  - Valid URLs: {valid_count}\")\n",
    "        logger.info(f\"  - Missing URLs: {missing_count}\")\n",
    "        logger.info(f\"  - Invalid URLs: {invalid_count}\")\n",
    "        return results\n",
    "    \n",
    "    def get_invalid_urls(self):\n",
    "        \"\"\"Get records with invalid URLs\"\"\"\n",
    "        validated = self.validate_urls()\n",
    "        return validated[~validated['url_valid'] & ~validated['url_missing']]\n",
    "    \n",
    "    def check_reachability(self, timeout=5, max_workers=10):\n",
    "        \"\"\"Check if URLs are reachable (optional)\"\"\"\n",
    "        import requests\n",
    "        from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "        \n",
    "        def check_url(url):\n",
    "            if pd.isna(url):\n",
    "                return None\n",
    "            try:\n",
    "                url = url.strip()\n",
    "                if not re.match(r'^https?://', url, re.IGNORECASE):\n",
    "                    url = 'http://' + url\n",
    "                response = requests.head(url, timeout=timeout, allow_redirects=True)\n",
    "                return response.status_code < 400\n",
    "            except: \n",
    "                return False\n",
    "        \n",
    "        urls = self.df[self.url_column].dropna().unique()\n",
    "        reachability = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {executor.submit(check_url, url): url for url in urls}\n",
    "            for future in as_completed(futures):\n",
    "                url = futures[future]\n",
    "                reachability[url] = future.result()\n",
    "        \n",
    "        results = self.df.copy()\n",
    "        results['url_reachable'] = results[self.url_column].map(reachability)\n",
    "        return results\n",
    "    \n",
    "    def clean_urls(self):\n",
    "        \"\"\"Remove records with invalid URLs\"\"\"\n",
    "        validated = self.validate_urls()\n",
    "        cleaned = validated[validated['url_valid'] | validated['url_missing']]\n",
    "        invalid = validated[~validated['url_valid'] & ~validated['url_missing']]\n",
    "\n",
    "        logger.info(f\"Removed {len(invalid)} records with invalid URLs\")\n",
    "        logger.info(f\"Retained {len(cleaned)} records with valid or missing URLs\")\n",
    "        \n",
    "        return cleaned.drop(columns=['url_valid', 'url_missing']).reset_index(drop=True), invalid\n",
    "    \n",
    "    \n",
    "# Usage:\n",
    "validator = URLValidator(cleaned_df)\n",
    "print(f\"Invalid URLs: {len(validator.get_invalid_urls())}\")\n",
    "cleaned_df, invalid_urls = validator.clean_urls()\n",
    "# \n",
    "# # Optional: Check reachability (slower), had to stop it because it took over 11mins and it wasn't done\n",
    "# reachable_df = validator.check_reachability()\n",
    "# print(reachable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8619dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2022</td>\n",
       "      <td>Kaedim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinetix</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D animation with AI, democratiz...</td>\n",
       "      <td>https://www.kinetix.tech</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>Kinetix</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D modeling with AI-powered, tex...</td>\n",
       "      <td>https://nv-tlabs.github.io</td>\n",
       "      <td>Free</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize animation with AI-driven motion ...</td>\n",
       "      <td>https://www.deepmotion.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize VFX: automate animation, lightin...</td>\n",
       "      <td>https://wonderdynamics.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2024</td>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tool Name Category Primary Function  \\\n",
       "0           Kaedim       3D               3D   \n",
       "1          Kinetix       3D               3D   \n",
       "2  GET3D by NVIDIA       3D               3D   \n",
       "3       DeepMotion       3D               3D   \n",
       "4    Wonder Studio       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "1  Revolutionize 3D animation with AI, democratiz...   \n",
       "2  Revolutionize 3D modeling with AI-powered, tex...   \n",
       "3  Revolutionize animation with AI-driven motion ...   \n",
       "4  Revolutionize VFX: automate animation, lightin...   \n",
       "\n",
       "                      Website Pricing Model Key Features Target Users  \\\n",
       "0    https://www.kaedim3d.com          Paid  See website      General   \n",
       "1    https://www.kinetix.tech          Paid  See website      General   \n",
       "2  https://nv-tlabs.github.io          Free  See website      General   \n",
       "3  https://www.deepmotion.com      Freemium  See website      General   \n",
       "4  https://wonderdynamics.com      Freemium  See website      General   \n",
       "\n",
       "  Launch Year          Company  category_rank  ID  Category_code  \\\n",
       "0        2022           Kaedim              1   1              0   \n",
       "1        2024          Kinetix              2   2              0   \n",
       "2        2024  GET3D by NVIDIA              3   3              0   \n",
       "3        2024       DeepMotion              4   4              0   \n",
       "4        2024    Wonder Studio              5   5              0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0            4.26             0  \n",
       "1            3.71             0  \n",
       "2            3.63             0  \n",
       "3            3.60             0  \n",
       "4            4.26             0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4f5e3",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2e823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53489 entries, 0 to 53488\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Tool Name         53489 non-null  object \n",
      " 1   Category          53489 non-null  object \n",
      " 2   Primary Function  53489 non-null  object \n",
      " 3   Description       53489 non-null  object \n",
      " 4   Website           53489 non-null  object \n",
      " 5   Pricing Model     53489 non-null  object \n",
      " 6   Key Features      53489 non-null  object \n",
      " 7   Target Users      53489 non-null  object \n",
      " 8   Launch Year       53489 non-null  object \n",
      " 9   Company           53489 non-null  object \n",
      " 10  category_rank     53489 non-null  int64  \n",
      " 11  ID                53489 non-null  int64  \n",
      " 12  Category_code     53489 non-null  int64  \n",
      " 13  average_rating    53489 non-null  float64\n",
      " 14  review_count      53489 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(10)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa733d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition = cleaned_df[\"Launch Year\"]<2019\n",
    "# filtered = cleaned_df[condition]\n",
    "# print(filtered)\n",
    "\n",
    "# # print(cleaned_df[cleaned_df[\"Launch Year\"]<2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14908cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Launch Year'] = pd.to_numeric(df['Launch Year'], errors='coerce').astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a35314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec7925",
   "metadata": {},
   "source": [
    "## Validate Launch Year: Range checks  Missing or future values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8797ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:34:24,953 - INFO - YearValidator initialized\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntCastingNaNError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m corrected, pd.DataFrame(corrections)\n\u001b[32m    119\u001b[39m validator = YearValidator(cleaned_df)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m cleaned_df, invalid_records = validator.clean_years(strategy=\u001b[33m'\u001b[39m\u001b[33mnullify\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# # Or attempt corrections first\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# corrected_df, corrections_log = validator.correct_years()\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mYearValidator.get_summary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_summary\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     53\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Summary of year validation issues\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     validated = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate_years\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     summary = validated[\u001b[33m'\u001b[39m\u001b[33myear_issue\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n\u001b[32m     56\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYear validation summary:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mYearValidator.validate_years\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     23\u001b[39m results = \u001b[38;5;28mself\u001b[39m.df.copy()\n\u001b[32m     24\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33myear_missing\u001b[39m\u001b[33m'\u001b[39m] = results[\u001b[38;5;28mself\u001b[39m.year_column].isna()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33myear_valid\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43myear_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_valid_year\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Categorize invalid reasons\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcategorize_invalid\u001b[39m(row):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mYearValidator.is_valid_year\u001b[39m\u001b[34m(self, year)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_valid_year\u001b[39m(\u001b[38;5;28mself\u001b[39m, year):\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check if year is numeric and within range\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mLaunch Year\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLaunch Year\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mint64\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.isna(year):\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Missing, not invalid\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\generic.py:6665\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6659\u001b[39m     results = [\n\u001b[32m   6660\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6661\u001b[39m     ]\n\u001b[32m   6663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6664\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6665\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6666\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6667\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:449\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    447\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:101\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(\n\u001b[32m     97\u001b[39m         arr, skipna=skipna, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     98\u001b[39m     ).reshape(shape)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.issubdtype(arr.dtype, np.floating) \u001b[38;5;129;01mand\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_np_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:145\u001b[39m, in \u001b[36m_astype_float_to_int_nansafe\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(values).all():\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values >= \u001b[32m0\u001b[39m).all():\n",
      "\u001b[31mIntCastingNaNError\u001b[39m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "class YearValidator:\n",
    "    def __init__(self, df, year_column='Launch Year', min_year=2019, max_year=2025):\n",
    "        self.df = df.copy()\n",
    "        self.year_column = year_column\n",
    "        self.min_year = min_year\n",
    "        self.max_year = max_year or pd.Timestamp.now().year\n",
    "        logger.info(f\"YearValidator initialized\")\n",
    "        \n",
    "    def is_valid_year(self, year):\n",
    "        \"\"\"Check if year is numeric and within range\"\"\"\n",
    "\n",
    "        if pd.isna(year):\n",
    "            return None  # Missing, not invalid\n",
    "        try:\n",
    "            year_int = int(float(year))\n",
    "            return self.min_year <= year_int <= self.max_year\n",
    "        except (ValueError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    def validate_years(self):\n",
    "        \"\"\"Validate all years and categorize issues\"\"\"\n",
    "        results = self.df.copy()\n",
    "        results['year_missing'] = results[self.year_column].isna()\n",
    "        results['year_valid'] = results[self.year_column].apply(self.is_valid_year)\n",
    "        \n",
    "        # Categorize invalid reasons\n",
    "        def categorize_invalid(row):\n",
    "            if row['year_missing']:\n",
    "                return 'missing'\n",
    "            if row['year_valid']:\n",
    "                return 'valid'\n",
    "            try:\n",
    "                year_int = int(float(row[self.year_column]))\n",
    "                if year_int > self.max_year:\n",
    "                    return 'future'\n",
    "                if year_int < self.min_year:\n",
    "                    return 'too_old'\n",
    "            except:\n",
    "                return 'non_numeric'\n",
    "            return 'invalid'\n",
    "        \n",
    "        results['year_issue'] = results.apply(categorize_invalid, axis=1)\n",
    "        logger.info(f\"Year validation complete: {len(results)} records processed\")\n",
    "        return results\n",
    "    \n",
    "    def get_invalid_years(self):\n",
    "        \"\"\"Get records with invalid years\"\"\"\n",
    "        validated = self.validate_years()\n",
    "        return validated[validated['year_issue'].isin(['future', 'too_old', 'non_numeric'])]\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Summary of year validation issues\"\"\"\n",
    "        validated = self.validate_years()\n",
    "        summary = validated['year_issue'].value_counts()\n",
    "        logger.info(f\"Year validation summary:\\n{summary}\")\n",
    "        return summary\n",
    "    \n",
    "    def clean_years(self, strategy='remove'):\n",
    "        \"\"\"\n",
    "        Clean invalid years\n",
    "        strategy: 'remove' (delete rows) or 'nullify' (set to NaN)\n",
    "        \"\"\"\n",
    "        validated = self.validate_years()\n",
    "        \n",
    "        if strategy == 'remove':\n",
    "            cleaned = validated[validated['year_issue'].isin(['valid', 'missing'])]\n",
    "            invalid = validated[~validated['year_issue'].isin(['valid', 'missing'])]\n",
    "        elif strategy == 'nullify':\n",
    "            cleaned = validated.copy()\n",
    "            mask = ~cleaned['year_issue'].isin(['valid', 'missing'])\n",
    "            cleaned.loc[mask, self.year_column] = np.nan\n",
    "            invalid = validated[mask]\n",
    "        else:\n",
    "            raise ValueError(\"strategy must be 'remove' or 'nullify'\")\n",
    "        \n",
    "        # Drop helper columns\n",
    "        cols_to_drop = ['year_missing', 'year_valid', 'year_issue']\n",
    "        cleaned = cleaned.drop(columns=cols_to_drop)\n",
    "        logger.info(f\"Cleaning complete: {len(cleaned)} records remaining\")\n",
    "        return cleaned.reset_index(drop=True), invalid\n",
    "    \n",
    "    def correct_years(self):\n",
    "        \"\"\"Attempt to correct obvious errors\"\"\"\n",
    "        corrected = self.df.copy()\n",
    "        corrections = []\n",
    "        \n",
    "        for idx, row in corrected.iterrows():\n",
    "            year = row[self.year_column]\n",
    "            if pd.isna(year):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                year_int = int(float(year))\n",
    "                original = year_int\n",
    "                \n",
    "                # Common errors: 2-digit years\n",
    "                if 0 <= year_int <= 99:\n",
    "                    year_int = 2000 + year_int if year_int <= self.max_year % 100 else 1900 + year_int\n",
    "                \n",
    "                # Future years: might be typo (e.g., 2025 instead of 2015)\n",
    "                if year_int > self.max_year:\n",
    "                    continue  # Can't reliably correct\n",
    "                \n",
    "                if year_int != original and self.min_year <= year_int <= self.max_year:\n",
    "                    corrected.at[idx, self.year_column] = year_int\n",
    "                    corrections.append({\n",
    "                        'index': idx,\n",
    "                        'original': original,\n",
    "                        'corrected': year_int,\n",
    "                        'tool': row.get('Tool Name', 'Unknown')\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        logger.info(f\"Corrected {len(corrections)} year values\")\n",
    "        return corrected, pd.DataFrame(corrections)\n",
    "\n",
    "\n",
    "validator = YearValidator(cleaned_df)\n",
    "validator.get_summary()\n",
    "cleaned_df, invalid_records = validator.clean_years(strategy='nullify')\n",
    "# \n",
    "# # Or attempt corrections first\n",
    "# corrected_df, corrections_log = validator.correct_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tool Name', 'Category', 'Primary Function', 'Description', 'Website',\n",
       "       'Pricing Model', 'Key Features', 'Target Users', 'Launch Year',\n",
       "       'Company', 'category_rank', 'ID', 'Category_code', 'average_rating',\n",
       "       'review_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2a4d5",
   "metadata": {},
   "source": [
    "## Validate numeric columns: average_rating bounds  review_count non-negativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:15:13,325 - INFO - Invalid ratings: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:15:13,327 - INFO - Invalid review counts: 0\n",
      "2026-02-12 23:15:13,368 - INFO - Cleaned 0 records with invalid numeric values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'invalid_ratings': 0, 'invalid_reviews': 0, 'total_rows': 53489}\n"
     ]
    }
   ],
   "source": [
    "class NumericValidator:\n",
    "    def __init__(self, df, rating_col='average_rating', review_col='review_count', \n",
    "                 rating_min=0, rating_max=5):\n",
    "        self.df = df.copy()\n",
    "        self.rating_col = rating_col\n",
    "        self.review_col = review_col\n",
    "        self.rating_min = rating_min\n",
    "        self.rating_max = rating_max\n",
    "        \n",
    "    def validate_ratings(self):\n",
    "        \"\"\"Check if ratings are within valid bounds\"\"\"\n",
    "        ratings = self.df[self.rating_col].copy()\n",
    "        mask = (ratings < self.rating_min) | (ratings > self.rating_max)\n",
    "        return self.df[mask & ratings.notna()]\n",
    "    \n",
    "    def validate_reviews(self):\n",
    "        \"\"\"Check if review counts are non-negative integers\"\"\"\n",
    "        reviews = self.df[self.review_col].copy()\n",
    "        \n",
    "        # Check for negative or non-integer values\n",
    "        mask_negative = reviews < 0\n",
    "        mask_non_integer = reviews != reviews.astype(int)\n",
    "        mask = (mask_negative | mask_non_integer) & reviews.notna()\n",
    "        \n",
    "        return self.df[mask]\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get validation summary\"\"\"\n",
    "        invalid_ratings = len(self.validate_ratings())\n",
    "        invalid_reviews = len(self.validate_reviews())\n",
    "        \n",
    "        summary = {\n",
    "            'invalid_ratings': invalid_ratings,\n",
    "            'invalid_reviews': invalid_reviews,\n",
    "            'total_rows': len(self.df)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Invalid ratings: {invalid_ratings}\")\n",
    "        logger.info(f\"Invalid review counts: {invalid_reviews}\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def flag_records(self):\n",
    "        \"\"\"Add flag columns for invalid values\"\"\"\n",
    "        flagged = self.df.copy()\n",
    "        \n",
    "        ratings = flagged[self.rating_col]\n",
    "        reviews = flagged[self.review_col]\n",
    "        \n",
    "        flagged['invalid_rating'] = ((ratings < self.rating_min) | (ratings > self.rating_max)) & ratings.notna()\n",
    "        flagged['invalid_review'] = ((reviews < 0) | (reviews != reviews.astype(int))) & reviews.notna()\n",
    "        \n",
    "        return flagged\n",
    "    \n",
    "    def clean_records(self, strategy='remove'):\n",
    "        \"\"\"\n",
    "        Clean invalid records\n",
    "        strategy: 'remove' (delete rows) or 'nullify' (set to NaN)\n",
    "        \"\"\"\n",
    "        invalid_ratings = self.validate_ratings()\n",
    "        invalid_reviews = self.validate_reviews()\n",
    "        invalid_indices = invalid_ratings.index.union(invalid_reviews.index)\n",
    "        \n",
    "        if strategy == 'remove':\n",
    "            cleaned = self.df[~self.df.index.isin(invalid_indices)]\n",
    "            invalid = self.df[self.df.index.isin(invalid_indices)]\n",
    "        elif strategy == 'nullify':\n",
    "            cleaned = self.df.copy()\n",
    "            \n",
    "            ratings = cleaned[self.rating_col]\n",
    "            mask_rating = ((ratings < self.rating_min) | (ratings > self.rating_max)) & ratings.notna()\n",
    "            cleaned.loc[mask_rating, self.rating_col] = np.nan\n",
    "            \n",
    "            reviews = cleaned[self.review_col]\n",
    "            mask_review = ((reviews < 0) | (reviews != reviews.astype(int))) & reviews.notna()\n",
    "            cleaned.loc[mask_review, self.review_col] = np.nan\n",
    "            \n",
    "            invalid = self.df[self.df.index.isin(invalid_indices)]\n",
    "        else:\n",
    "            raise ValueError(\"strategy must be 'remove' or 'nullify'\")\n",
    "        \n",
    "        logger.info(f\"Cleaned {len(invalid)} records with invalid numeric values\")\n",
    "        return cleaned.reset_index(drop=True), invalid\n",
    "\n",
    "\n",
    "validator = NumericValidator(cleaned_df, rating_min=0, rating_max=5)\n",
    "print(validator.get_summary())\n",
    "flagged_df = validator.flag_records()\n",
    "# # or\n",
    "cleaned_df, invalid = validator.clean_records(strategy='nullify')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e01d73",
   "metadata": {},
   "source": [
    "## Normalize text fields: Casing  Whitespace  Encoding issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da268449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:15:22,387 - INFO - Standardized 10 text columns\n"
     ]
    }
   ],
   "source": [
    "class TextStandardizer:\n",
    "    def __init__(self, df, text_columns=None):\n",
    "        self.df = df.copy()\n",
    "        self.text_columns = text_columns or self.df.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Standardize single text value\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Strip leading/trailing whitespace\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Normalize unicode characters\n",
    "        text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def standardize_all(self, case_rules=None):\n",
    "        \"\"\"\n",
    "        Standardize all text columns\n",
    "        case_rules: dict mapping column names to case types\n",
    "        \"\"\"\n",
    "        standardized = self.df.copy()\n",
    "        \n",
    "        # Default case rules\n",
    "        if case_rules is None:\n",
    "            case_rules = {\n",
    "                'Tool Name': 'title',\n",
    "                'Category': 'title',\n",
    "                'Company': 'title',\n",
    "                'Primary Function': 'sentence',\n",
    "                'Description': 'sentence',\n",
    "                'Pricing Model': 'title',\n",
    "                'Target Users': 'title'\n",
    "            }\n",
    "        \n",
    "        # Clean whitespace and encoding for all text columns\n",
    "        for col in self.text_columns:\n",
    "            if col in standardized.columns:\n",
    "                standardized[col] = standardized[col].apply(self.clean_text)\n",
    "        \n",
    "        # Apply case rules\n",
    "        for col, case_type in case_rules.items():\n",
    "            if col in standardized.columns:\n",
    "                if case_type == 'title':\n",
    "                    standardized[col] = standardized[col].str.title()\n",
    "                elif case_type == 'lower':\n",
    "                    standardized[col] = standardized[col].str.lower()\n",
    "                elif case_type == 'upper':\n",
    "                    standardized[col] = standardized[col].str.upper()\n",
    "                elif case_type == 'sentence':\n",
    "                    standardized[col] = standardized[col].apply(\n",
    "                        lambda x: x.capitalize() if isinstance(x, str) else x\n",
    "                    )\n",
    "        \n",
    "        logger.info(f\"Standardized {len(self.text_columns)} text columns\")\n",
    "        return standardized\n",
    "    \n",
    "    def get_changes_summary(self, standardized_df):\n",
    "        \"\"\"Compare original vs standardized data\"\"\"\n",
    "        changes = []\n",
    "        \n",
    "        for col in self.text_columns:\n",
    "            if col in self.df.columns:\n",
    "                mask = self.df[col] != standardized_df[col]\n",
    "                changed_count = mask.sum()\n",
    "                if changed_count > 0:\n",
    "                    changes.append({\n",
    "                        'column': col,\n",
    "                        'changes': changed_count,\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(changes)\n",
    "\n",
    "# Usage:\n",
    "standardizer = TextStandardizer(cleaned_df)\n",
    "cleaned_df = standardizer.standardize_all()\n",
    "# \n",
    "# \n",
    "# # See what changed\n",
    "changes = standardizer.get_changes_summary(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98058c",
   "metadata": {},
   "source": [
    "## Flag descriptions that are too short or non-informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:15:25,208 - INFO - Flagged 10485 invalid descriptions\n",
      "2026-02-12 23:15:25,321 - INFO - Total flagged: 10485\n",
      "2026-02-12 23:15:25,324 - INFO - \n",
      "desc_flag\n",
      "meaningless    10484\n",
      "few_words          1\n",
      "Name: count, dtype: int64\n",
      "2026-02-12 23:15:25,841 - INFO - Flagged 10485 invalid descriptions\n"
     ]
    }
   ],
   "source": [
    "class DescriptionValidator:\n",
    "    def __init__(self, df, description_col='Description', min_length=10, min_words=3):\n",
    "        self.df = df.copy()\n",
    "        self.description_col = description_col\n",
    "        self.min_length = min_length\n",
    "        self.min_words = min_words\n",
    "        self.meaningless = ['n/a', 'na', 'none', 'null', 'tbd', 'tba', 'coming soon',\n",
    "                           'no description', 'not available', 'see website', 'lorem ipsum']\n",
    "        \n",
    "    def get_flag_reason(self, text):\n",
    "        \"\"\"Check description and return reason if invalid\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return 'missing'\n",
    "        \n",
    "        text_str = str(text).strip()\n",
    "        text_lower = text_str.lower()\n",
    "        reasons = []\n",
    "        \n",
    "        if len(text_str) < self.min_length:\n",
    "            reasons.append('too_short')\n",
    "        if len(text_str.split()) < self.min_words:\n",
    "            reasons.append('few_words')\n",
    "        if any(pattern in text_lower for pattern in self.meaningless):\n",
    "            reasons.append('meaningless')\n",
    "        \n",
    "        return ', '.join(reasons) if reasons else None\n",
    "    \n",
    "    def flag_descriptions(self):\n",
    "        \"\"\"Add flag column for invalid descriptions\"\"\"\n",
    "        flagged = self.df.copy()\n",
    "        flagged['desc_flag'] = flagged[self.description_col].apply(self.get_flag_reason)\n",
    "        \n",
    "        invalid_count = flagged['desc_flag'].notna().sum()\n",
    "        logger.info(f\"Flagged {invalid_count} invalid descriptions\")\n",
    "        \n",
    "        return flagged\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get summary of flagged descriptions\"\"\"\n",
    "        flagged = self.flag_descriptions()\n",
    "        total_flagged = flagged['desc_flag'].notna().sum()\n",
    "        \n",
    "        reasons = flagged['desc_flag'].dropna().str.split(', ').explode().value_counts()\n",
    "        \n",
    "        logger.info(f\"Total flagged: {total_flagged}\")\n",
    "        logger.info(f\"\\n{reasons}\")\n",
    "        \n",
    "        return reasons\n",
    "\n",
    "# Usage:\n",
    "validator = DescriptionValidator(cleaned_df, min_length=10, min_words=3)\n",
    "summary = validator.get_summary()\n",
    "flagged_df = validator.flag_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:15:39,938 - INFO - Cleaned data saved successfully\n"
     ]
    }
   ],
   "source": [
    "# def save_cleaned_data(data: pd.DataFrame, filename: str, index: bool = False):\n",
    "#     try: \n",
    "#         data.to_csv(filename, index = False)\n",
    "#         logger.info(\n",
    "#             \"Cleaned data saved successfully\")\n",
    "#     except IOError as e:\n",
    "#         logger.error(\n",
    "#             f\"Failed to save cleaned data to {filename}\",\n",
    "#             exc_info=True\n",
    "#         )\n",
    "\n",
    "# save_cleaned_data(cleaned_df, filename=\"Cleaned_AI_Tools_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c7296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54909, 15)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paths = r\"C:\\Users\\owner\\Desktop\\Files_Deep_Learning\\NeuraGuide\\Cleaned_AI_Tools.csv\"\n",
    "# dff = load_data(path=paths)\n",
    "\n",
    "# dff.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
