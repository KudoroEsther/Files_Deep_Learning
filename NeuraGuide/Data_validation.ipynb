{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84ced37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n",
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing libraries...\")\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import logging\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "print(\"Libraries imported!\")\n",
    "\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21376593",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"C:\\Users\\owner\\Desktop\\Files_Deep_Learning\\NeuraGuide\\AI_Tools.csv\"\n",
    "\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "\n",
    "df = load_data(url)\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6ce8ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tool Name', 'Category', 'Primary Function', 'Description', 'Website',\n",
       "       'Pricing Model', 'Key Features', 'Target Users', 'Launch Year',\n",
       "       'Company', 'category_rank', 'ID', 'Category_code', 'average_rating',\n",
       "       'review_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f032e5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinetix</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D animation with AI, democratiz...</td>\n",
       "      <td>https://www.kinetix.tech</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D modeling with AI-powered, tex...</td>\n",
       "      <td>https://nv-tlabs.github.io</td>\n",
       "      <td>Free</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize animation with AI-driven motion ...</td>\n",
       "      <td>https://www.deepmotion.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize VFX: automate animation, lightin...</td>\n",
       "      <td>https://wonderdynamics.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tool Name Category Primary Function  \\\n",
       "0           Kaedim       3D               3D   \n",
       "1          Kinetix       3D               3D   \n",
       "2  GET3D by NVIDIA       3D               3D   \n",
       "3       DeepMotion       3D               3D   \n",
       "4    Wonder Studio       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "1  Revolutionize 3D animation with AI, democratiz...   \n",
       "2  Revolutionize 3D modeling with AI-powered, tex...   \n",
       "3  Revolutionize animation with AI-driven motion ...   \n",
       "4  Revolutionize VFX: automate animation, lightin...   \n",
       "\n",
       "                      Website Pricing Model Key Features Target Users  \\\n",
       "0    https://www.kaedim3d.com          Paid  See website      General   \n",
       "1    https://www.kinetix.tech          Paid  See website      General   \n",
       "2  https://nv-tlabs.github.io          Free  See website      General   \n",
       "3  https://www.deepmotion.com      Freemium  See website      General   \n",
       "4  https://wonderdynamics.com      Freemium  See website      General   \n",
       "\n",
       "  Launch Year  Company  category_rank  ID  Category_code  average_rating  \\\n",
       "0     Unknown  Unknown              1   1              0            0.00   \n",
       "1     Unknown  Unknown              2   2              0            0.00   \n",
       "2     Unknown  Unknown              3   3              0            0.00   \n",
       "3     Unknown  Unknown              4   4              0            0.00   \n",
       "4     Unknown  Unknown              5   5              0            0.00   \n",
       "\n",
       "   review_count  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aefed848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54910, 15)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16834a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Year    1420\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced \"Unknown\" with a range of years from 2020 to 2025\n",
    "df[\"Launch Year\"] = np.where(df[\"Launch Year\"] == \"Unknown\", \n",
    "                             np.random.randint(2020, 2025, size=len(df)), \n",
    "                             df[\"Launch Year\"]) \n",
    "\n",
    "# Replaced 0.0 ratings with a range of values from 1 - 5 with a preference for high values\n",
    "df[\"average_rating\"] = np.where(df[\"average_rating\"] == 0.0, \n",
    "                             np.round(1 + 4 * np.random.beta(a=5, b=1.5, size=len(df)), 2), \n",
    "                             df[\"average_rating\"]) \n",
    "\n",
    "#Replaced 'Unknown' with the Tool Name\n",
    "mask = df[\"Company\"] == \"Unknown\"\n",
    "df.loc[mask, \"Company\"] = df.loc[mask, \"Tool Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21e6dfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Kaedim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tool Name Category Primary Function  \\\n",
       "0    Kaedim       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "\n",
       "                    Website Pricing Model Key Features Target Users  \\\n",
       "0  https://www.kaedim3d.com          Paid  See website      General   \n",
       "\n",
       "  Launch Year Company  category_rank  ID  Category_code  average_rating  \\\n",
       "0        2020  Kaedim              1   1              0            3.93   \n",
       "\n",
       "   review_count  \n",
       "0             0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13773ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54910 entries, 0 to 54909\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Tool Name         54910 non-null  object \n",
      " 1   Category          54910 non-null  object \n",
      " 2   Primary Function  54910 non-null  object \n",
      " 3   Description       54910 non-null  object \n",
      " 4   Website           54910 non-null  object \n",
      " 5   Pricing Model     54910 non-null  object \n",
      " 6   Key Features      54910 non-null  object \n",
      " 7   Target Users      54910 non-null  object \n",
      " 8   Launch Year       53490 non-null  object \n",
      " 9   Company           54910 non-null  object \n",
      " 10  category_rank     54910 non-null  int64  \n",
      " 11  ID                54910 non-null  int64  \n",
      " 12  Category_code     54910 non-null  int64  \n",
      " 13  average_rating    54910 non-null  float64\n",
      " 14  review_count      54910 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(10)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aebe5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Year    1420\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53239363",
   "metadata": {},
   "source": [
    "## Identify and Remove Duplicate Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49d7b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicates\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(df):\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"Duplicated rows: {duplicates}\")\n",
    "        # df = df.drop_duplicates(inplace=True)\n",
    "        # dropped = df.duplicated().sum()\n",
    "        # print(f\"\\nDuplicates: {dropped}\")\n",
    "    else:\n",
    "        print(\"There are no duplicates\")\n",
    "\n",
    "check_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3bf527bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:39,969 - INFO - DuplicateHandler initialized with 54910 records\n",
      "2026-02-12 23:55:39,974 - INFO - Duplicate detection keys: Tool Name, Company, Website\n",
      "2026-02-12 23:55:40,062 - INFO - Found 0 duplicate records in 0 groups\n",
      "2026-02-12 23:55:40,064 - INFO - No duplicates found\n"
     ]
    }
   ],
   "source": [
    "# Detect duplicate entries using Tool Name, Company, and Website. Decide which record to keep and remove the rest using deterministic logic.\n",
    "\n",
    "class DuplicateHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.duplicate_keys = ['Tool Name', 'Company', 'Website']\n",
    "        logger.info(f\"DuplicateHandler initialized with {len(self.df)} records\")\n",
    "        logger.info(f\"Duplicate detection keys: {', '.join(self.duplicate_keys)}\")\n",
    "        \n",
    "    def find_duplicates(self):\n",
    "        \"\"\"Identify duplicate groups\"\"\"\n",
    "        duplicates = self.df[self.df.duplicated(subset=self.duplicate_keys, keep=False)]\n",
    "        logger.info(f\"Found {len(duplicates)} duplicate records in {duplicates.groupby(self.duplicate_keys, dropna=False).ngroups} groups\")\n",
    "        return duplicates\n",
    "    \n",
    "    def rank_records(self, group):\n",
    "        \"\"\"Score records: higher is better\"\"\"\n",
    "        scores = pd.DataFrame(index=group.index)\n",
    "        scores['completeness'] = group.notna().sum(axis=1)\n",
    "        scores['reviews'] = group['review_count'].fillna(0)\n",
    "        scores['rating'] = group['average_rating'].fillna(0)\n",
    "        scores['recency'] = group['Launch Year'].fillna(0)\n",
    "        scores['position'] = -np.arange(len(group))  # negative for ascending\n",
    "        return scores.sum(axis=1).idxmax()\n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Keep best record per duplicate group\"\"\"\n",
    "        dupes = self.find_duplicates()\n",
    "        if dupes.empty:\n",
    "            logger.info(\"No duplicates found\")\n",
    "            return self.df, pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "            keep_indices = dupes.groupby(self.duplicate_keys, dropna=False).apply(self.rank_records)\n",
    "            removed = self.df[self.df.index.isin(dupes.index) & ~self.df.index.isin(keep_indices)]\n",
    "            cleaned = self.df[~self.df.index.isin(dupes.index) | self.df.index.isin(keep_indices)]\n",
    "            \n",
    "            logger.info(f\"Removed {len(removed)} duplicate records\")\n",
    "            logger.info(f\"Retained {len(cleaned)} unique records\")\n",
    "            return cleaned.reset_index(drop=True), removed\n",
    "\n",
    "# Usage:\n",
    "handler = DuplicateHandler(df)\n",
    "cleaned_df, removed_records = handler.remove_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86b667c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54910, 15)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12b8736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Year    1420\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f48ce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Kaedim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinetix</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D animation with AI, democratiz...</td>\n",
       "      <td>https://www.kinetix.tech</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Kinetix</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D modeling with AI-powered, tex...</td>\n",
       "      <td>https://nv-tlabs.github.io</td>\n",
       "      <td>Free</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2022</td>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize animation with AI-driven motion ...</td>\n",
       "      <td>https://www.deepmotion.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2021</td>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize VFX: automate animation, lightin...</td>\n",
       "      <td>https://wonderdynamics.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tool Name Category Primary Function  \\\n",
       "0           Kaedim       3D               3D   \n",
       "1          Kinetix       3D               3D   \n",
       "2  GET3D by NVIDIA       3D               3D   \n",
       "3       DeepMotion       3D               3D   \n",
       "4    Wonder Studio       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "1  Revolutionize 3D animation with AI, democratiz...   \n",
       "2  Revolutionize 3D modeling with AI-powered, tex...   \n",
       "3  Revolutionize animation with AI-driven motion ...   \n",
       "4  Revolutionize VFX: automate animation, lightin...   \n",
       "\n",
       "                      Website Pricing Model Key Features Target Users  \\\n",
       "0    https://www.kaedim3d.com          Paid  See website      General   \n",
       "1    https://www.kinetix.tech          Paid  See website      General   \n",
       "2  https://nv-tlabs.github.io          Free  See website      General   \n",
       "3  https://www.deepmotion.com      Freemium  See website      General   \n",
       "4  https://wonderdynamics.com      Freemium  See website      General   \n",
       "\n",
       "  Launch Year          Company  category_rank  ID  Category_code  \\\n",
       "0        2020           Kaedim              1   1              0   \n",
       "1        2020          Kinetix              2   2              0   \n",
       "2        2022  GET3D by NVIDIA              3   3              0   \n",
       "3        2021       DeepMotion              4   4              0   \n",
       "4        2020    Wonder Studio              5   5              0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0            3.93             0  \n",
       "1            4.25             0  \n",
       "2            4.17             0  \n",
       "3            4.71             0  \n",
       "4            3.93             0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dac611",
   "metadata": {},
   "source": [
    "## Identify rows missing essential information such as Tool Name, Category, or Website. Flag or remove records based on defined rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "90e12e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:40,522 - INFO - Flagged 1420 records with missing values\n",
      "2026-02-12 23:55:40,575 - INFO - Removed 1420 rows with missing values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             missing_count  missing_pct\n",
      "Launch Year           1420         2.59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MissingDataHandler:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        # self.required_fields = required_fields or ['Tool Name', 'Category', 'Website']\n",
    "        \n",
    "    def find_missing(self):\n",
    "        \"\"\"Find rows with missing required fields\"\"\"\n",
    "        mask = self.df.isna().any(axis=1)\n",
    "        return self.df[mask]\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get missing data summary\"\"\"\n",
    "        summary = pd.DataFrame({\n",
    "            'missing_count': self.df.isna().sum(),\n",
    "            'missing_pct': (self.df.isna().sum() / len(self.df) * 100).round(2)\n",
    "        })\n",
    "        return summary[summary['missing_count'] > 0].sort_values('missing_count', ascending=False)\n",
    "    \n",
    "    def flag_records(self):\n",
    "        \"\"\"Add flag column for rows with missing data\"\"\"\n",
    "        flagged = self.df.copy()\n",
    "        flagged['has_missing'] = self.df.isna().any(axis=1)\n",
    "        logger.info(f\"Flagged {flagged['has_missing'].sum()} records with missing values\")\n",
    "        return flagged\n",
    "    \n",
    "    def remove_records(self):\n",
    "        \"\"\"Remove rows with missing required fields\"\"\"\n",
    "        missing = self.find_missing()\n",
    "        cleaned = self.df[~self.df.index.isin(missing.index)]\n",
    "        logger.info(f\"Removed {len(missing)} rows with missing values\")\n",
    "        return cleaned.reset_index(drop=True), missing\n",
    "\n",
    "# Usage:\n",
    "handler = MissingDataHandler(cleaned_df)\n",
    "print(handler.get_summary())\n",
    "flagged_df = handler.flag_records()\n",
    "# # or\n",
    "cleaned_df, removed = handler.remove_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6825227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4aeae8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['Launch Year'] = pd.to_numeric(cleaned_df['Launch Year'], errors='coerce').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afd80e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd695cc",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a18828",
   "metadata": {},
   "source": [
    "## Validate Website: URL format Dead / malformed links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63bd8f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:40,881 - INFO - URLValidator initialized for column: Website\n",
      "2026-02-12 23:55:40,885 - INFO - Total records to validate: 53490\n",
      "2026-02-12 23:55:43,338 - INFO - URL validation complete:\n",
      "2026-02-12 23:55:43,339 - INFO -   - Valid URLs: 53489\n",
      "2026-02-12 23:55:43,340 - INFO -   - Missing URLs: 0\n",
      "2026-02-12 23:55:43,341 - INFO -   - Invalid URLs: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URLs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:45,499 - INFO - URL validation complete:\n",
      "2026-02-12 23:55:45,500 - INFO -   - Valid URLs: 53489\n",
      "2026-02-12 23:55:45,501 - INFO -   - Missing URLs: 0\n",
      "2026-02-12 23:55:45,503 - INFO -   - Invalid URLs: 1\n",
      "2026-02-12 23:55:45,520 - INFO - Removed 1 records with invalid URLs\n",
      "2026-02-12 23:55:45,521 - INFO - Retained 53489 records with valid or missing URLs\n"
     ]
    }
   ],
   "source": [
    "class URLValidator:\n",
    "    def __init__(self, df, url_column='Website'):\n",
    "        self.df = df.copy()\n",
    "        self.url_column = url_column\n",
    "        logger.info(f\"URLValidator initialized for column: {url_column}\")\n",
    "        logger.info(f\"Total records to validate: {len(self.df)}\")\n",
    "        \n",
    "    def is_valid_url(self, url):\n",
    "        \"\"\"Check if URL is properly formatted\"\"\"\n",
    "        if pd.isna(url) or not isinstance(url, str):\n",
    "            return False\n",
    "        \n",
    "        # Basic pattern check\n",
    "        url = url.strip()\n",
    "        if not re.match(r'^https?://', url, re.IGNORECASE):\n",
    "            url = 'http://' + url\n",
    "        \n",
    "        try:\n",
    "            import validators\n",
    "            return validators.url(url) is True\n",
    "        except ImportError:\n",
    "            # Fallback to regex if validators not installed\n",
    "            pattern = re.compile(\n",
    "                r'^https?://'\n",
    "                r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}\\.?|'\n",
    "                r'localhost|'\n",
    "                r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'\n",
    "                r'(?::\\d+)?'\n",
    "                r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "            return bool(pattern.match(url))\n",
    "    \n",
    "    def validate_urls(self):\n",
    "        \"\"\"Validate all URLs and return results\"\"\"\n",
    "        results = self.df.copy()\n",
    "        results['url_valid'] = results[self.url_column].apply(self.is_valid_url)\n",
    "        results['url_missing'] = results[self.url_column].isna()\n",
    "\n",
    "        valid_count = results['url_valid'].sum()\n",
    "        missing_count = results['url_missing'].sum()\n",
    "        invalid_count = (~results['url_valid'] & ~results['url_missing']).sum()\n",
    "\n",
    "        logger.info(f\"URL validation complete:\")\n",
    "        logger.info(f\"  - Valid URLs: {valid_count}\")\n",
    "        logger.info(f\"  - Missing URLs: {missing_count}\")\n",
    "        logger.info(f\"  - Invalid URLs: {invalid_count}\")\n",
    "        return results\n",
    "    \n",
    "    def get_invalid_urls(self):\n",
    "        \"\"\"Get records with invalid URLs\"\"\"\n",
    "        validated = self.validate_urls()\n",
    "        return validated[~validated['url_valid'] & ~validated['url_missing']]\n",
    "    \n",
    "    def check_reachability(self, timeout=5, max_workers=10):\n",
    "        \"\"\"Check if URLs are reachable (optional)\"\"\"\n",
    "        import requests\n",
    "        from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "        \n",
    "        def check_url(url):\n",
    "            if pd.isna(url):\n",
    "                return None\n",
    "            try:\n",
    "                url = url.strip()\n",
    "                if not re.match(r'^https?://', url, re.IGNORECASE):\n",
    "                    url = 'http://' + url\n",
    "                response = requests.head(url, timeout=timeout, allow_redirects=True)\n",
    "                return response.status_code < 400\n",
    "            except: \n",
    "                return False\n",
    "        \n",
    "        urls = self.df[self.url_column].dropna().unique()\n",
    "        reachability = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {executor.submit(check_url, url): url for url in urls}\n",
    "            for future in as_completed(futures):\n",
    "                url = futures[future]\n",
    "                reachability[url] = future.result()\n",
    "        \n",
    "        results = self.df.copy()\n",
    "        results['url_reachable'] = results[self.url_column].map(reachability)\n",
    "        return results\n",
    "    \n",
    "    def clean_urls(self):\n",
    "        \"\"\"Remove records with invalid URLs\"\"\"\n",
    "        validated = self.validate_urls()\n",
    "        cleaned = validated[validated['url_valid'] | validated['url_missing']]\n",
    "        invalid = validated[~validated['url_valid'] & ~validated['url_missing']]\n",
    "\n",
    "        logger.info(f\"Removed {len(invalid)} records with invalid URLs\")\n",
    "        logger.info(f\"Retained {len(cleaned)} records with valid or missing URLs\")\n",
    "        \n",
    "        return cleaned.drop(columns=['url_valid', 'url_missing']).reset_index(drop=True), invalid\n",
    "    \n",
    "    \n",
    "# Usage:\n",
    "validator = URLValidator(cleaned_df)\n",
    "print(f\"Invalid URLs: {len(validator.get_invalid_urls())}\")\n",
    "cleaned_df, invalid_urls = validator.clean_urls()\n",
    "# \n",
    "# # Optional: Check reachability (slower), had to stop it because it took over 11mins and it wasn't done\n",
    "# reachable_df = validator.check_reachability()\n",
    "# print(reachable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d8619dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Primary Function</th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Pricing Model</th>\n",
       "      <th>Key Features</th>\n",
       "      <th>Target Users</th>\n",
       "      <th>Launch Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>category_rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaedim</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Transform 2D images into high-quality 3D model...</td>\n",
       "      <td>https://www.kaedim3d.com</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Kaedim</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinetix</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D animation with AI, democratiz...</td>\n",
       "      <td>https://www.kinetix.tech</td>\n",
       "      <td>Paid</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Kinetix</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize 3D modeling with AI-powered, tex...</td>\n",
       "      <td>https://nv-tlabs.github.io</td>\n",
       "      <td>Free</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2022</td>\n",
       "      <td>GET3D by NVIDIA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize animation with AI-driven motion ...</td>\n",
       "      <td>https://www.deepmotion.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2021</td>\n",
       "      <td>DeepMotion</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>3D</td>\n",
       "      <td>3D</td>\n",
       "      <td>Revolutionize VFX: automate animation, lightin...</td>\n",
       "      <td>https://wonderdynamics.com</td>\n",
       "      <td>Freemium</td>\n",
       "      <td>See website</td>\n",
       "      <td>General</td>\n",
       "      <td>2020</td>\n",
       "      <td>Wonder Studio</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tool Name Category Primary Function  \\\n",
       "0           Kaedim       3D               3D   \n",
       "1          Kinetix       3D               3D   \n",
       "2  GET3D by NVIDIA       3D               3D   \n",
       "3       DeepMotion       3D               3D   \n",
       "4    Wonder Studio       3D               3D   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Transform 2D images into high-quality 3D model...   \n",
       "1  Revolutionize 3D animation with AI, democratiz...   \n",
       "2  Revolutionize 3D modeling with AI-powered, tex...   \n",
       "3  Revolutionize animation with AI-driven motion ...   \n",
       "4  Revolutionize VFX: automate animation, lightin...   \n",
       "\n",
       "                      Website Pricing Model Key Features Target Users  \\\n",
       "0    https://www.kaedim3d.com          Paid  See website      General   \n",
       "1    https://www.kinetix.tech          Paid  See website      General   \n",
       "2  https://nv-tlabs.github.io          Free  See website      General   \n",
       "3  https://www.deepmotion.com      Freemium  See website      General   \n",
       "4  https://wonderdynamics.com      Freemium  See website      General   \n",
       "\n",
       "   Launch Year          Company  category_rank  ID  Category_code  \\\n",
       "0         2020           Kaedim              1   1              0   \n",
       "1         2020          Kinetix              2   2              0   \n",
       "2         2022  GET3D by NVIDIA              3   3              0   \n",
       "3         2021       DeepMotion              4   4              0   \n",
       "4         2020    Wonder Studio              5   5              0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0            3.93             0  \n",
       "1            4.25             0  \n",
       "2            4.17             0  \n",
       "3            4.71             0  \n",
       "4            3.93             0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4f5e3",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd2e823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53489 entries, 0 to 53488\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Tool Name         53489 non-null  object \n",
      " 1   Category          53489 non-null  object \n",
      " 2   Primary Function  53489 non-null  object \n",
      " 3   Description       53489 non-null  object \n",
      " 4   Website           53489 non-null  object \n",
      " 5   Pricing Model     53489 non-null  object \n",
      " 6   Key Features      53489 non-null  object \n",
      " 7   Target Users      53489 non-null  object \n",
      " 8   Launch Year       53489 non-null  int64  \n",
      " 9   Company           53489 non-null  object \n",
      " 10  category_rank     53489 non-null  int64  \n",
      " 11  ID                53489 non-null  int64  \n",
      " 12  Category_code     53489 non-null  int64  \n",
      " 13  average_rating    53489 non-null  float64\n",
      " 14  review_count      53489 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(9)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "82a35314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec7925",
   "metadata": {},
   "source": [
    "## Validate Launch Year: Range checks  Missing or future values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad8797ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:45,900 - INFO - YearValidator initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:46,706 - INFO - Year validation complete: 53489 records processed\n",
      "2026-02-12 23:55:46,715 - INFO - Year validation summary:\n",
      "year_issue\n",
      "valid      53401\n",
      "too_old       88\n",
      "Name: count, dtype: int64\n",
      "2026-02-12 23:55:51,067 - INFO - Corrected 0 year values\n",
      "2026-02-12 23:55:51,814 - INFO - Year validation complete: 53489 records processed\n",
      "2026-02-12 23:55:51,845 - INFO - Cleaning complete: 53401 records remaining\n"
     ]
    }
   ],
   "source": [
    "class YearValidator:\n",
    "    def __init__(self, df, year_column='Launch Year', min_year=2015, max_year=2025):\n",
    "        self.df = df.copy()\n",
    "        self.year_column = year_column\n",
    "        self.min_year = min_year\n",
    "        self.max_year = max_year or pd.Timestamp.now().year\n",
    "        logger.info(f\"YearValidator initialized\")\n",
    "        \n",
    "    def is_valid_year(self, year):\n",
    "        \"\"\"Check if year is numeric and within range\"\"\"\n",
    "\n",
    "        if pd.isna(year):\n",
    "            return None  # Missing, not invalid\n",
    "        try:\n",
    "            year_int = int(float(year))\n",
    "            return self.min_year <= year_int <= self.max_year\n",
    "        except (ValueError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    def validate_years(self):\n",
    "        \"\"\"Validate all years and categorize issues\"\"\"\n",
    "        results = self.df.copy()\n",
    "        results['year_missing'] = results[self.year_column].isna()\n",
    "        results['year_valid'] = results[self.year_column].apply(self.is_valid_year)\n",
    "        \n",
    "        # Categorize invalid reasons\n",
    "        def categorize_invalid(row):\n",
    "            if row['year_missing']:\n",
    "                return 'missing'\n",
    "            if row['year_valid']:\n",
    "                return 'valid'\n",
    "            try:\n",
    "                year_int = int(float(row[self.year_column]))\n",
    "                if year_int > self.max_year:\n",
    "                    return 'future'\n",
    "                if year_int < self.min_year:\n",
    "                    return 'too_old'\n",
    "            except:\n",
    "                return 'non_numeric'\n",
    "            return 'invalid'\n",
    "        \n",
    "        results['year_issue'] = results.apply(categorize_invalid, axis=1)\n",
    "        logger.info(f\"Year validation complete: {len(results)} records processed\")\n",
    "        return results\n",
    "    \n",
    "    def get_invalid_years(self):\n",
    "        \"\"\"Get records with invalid years\"\"\"\n",
    "        validated = self.validate_years()\n",
    "        return validated[validated['year_issue'].isin(['future', 'too_old', 'non_numeric'])]\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Summary of year validation issues\"\"\"\n",
    "        validated = self.validate_years()\n",
    "        summary = validated['year_issue'].value_counts()\n",
    "        logger.info(f\"Year validation summary:\\n{summary}\")\n",
    "        return summary\n",
    "    \n",
    "    def clean_years(self, strategy='remove'):\n",
    "        \"\"\"\n",
    "        Clean invalid years\n",
    "        strategy: 'remove' (delete rows) or 'nullify' (set to NaN)\n",
    "        \"\"\"\n",
    "        validated = self.validate_years()\n",
    "        \n",
    "        if strategy == 'remove':\n",
    "            cleaned = validated[validated['year_issue'].isin(['valid', 'missing'])]\n",
    "            invalid = validated[~validated['year_issue'].isin(['valid', 'missing'])]\n",
    "        elif strategy == 'nullify':\n",
    "            cleaned = validated.copy()\n",
    "            mask = ~cleaned['year_issue'].isin(['valid', 'missing'])\n",
    "            cleaned.loc[mask, self.year_column] = np.nan\n",
    "            invalid = validated[mask]\n",
    "        else:\n",
    "            raise ValueError(\"strategy must be 'remove' or 'nullify'\")\n",
    "        \n",
    "        # Drop helper columns\n",
    "        cols_to_drop = ['year_missing', 'year_valid', 'year_issue']\n",
    "        cleaned = cleaned.drop(columns=cols_to_drop)\n",
    "        logger.info(f\"Cleaning complete: {len(cleaned)} records remaining\")\n",
    "        return cleaned.reset_index(drop=True), invalid\n",
    "    \n",
    "    def correct_years(self):\n",
    "        \"\"\"Attempt to correct obvious errors\"\"\"\n",
    "        corrected = self.df.copy()\n",
    "        corrections = []\n",
    "        \n",
    "        for idx, row in corrected.iterrows():\n",
    "            year = row[self.year_column]\n",
    "            if pd.isna(year):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                year_int = int(float(year))\n",
    "                original = year_int\n",
    "                \n",
    "                # Common errors: 2-digit years\n",
    "                if 0 <= year_int <= 99:\n",
    "                    year_int = 2000 + year_int if year_int <= self.max_year % 100 else 1900 + year_int\n",
    "                \n",
    "                # Future years: might be typo (e.g., 2025 instead of 2015)\n",
    "                if year_int > self.max_year:\n",
    "                    continue  # Can't reliably correct\n",
    "                \n",
    "                if year_int != original and self.min_year <= year_int <= self.max_year:\n",
    "                    corrected.at[idx, self.year_column] = year_int\n",
    "                    corrections.append({\n",
    "                        'index': idx,\n",
    "                        'original': original,\n",
    "                        'corrected': year_int,\n",
    "                        'tool': row.get('Tool Name', 'Unknown')\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        logger.info(f\"Corrected {len(corrections)} year values\")\n",
    "        return corrected, pd.DataFrame(corrections)\n",
    "\n",
    "\n",
    "validator = YearValidator(cleaned_df)\n",
    "validator.get_summary()\n",
    "corrected_df, corrections_log = validator.correct_years()\n",
    "cleaned_df, invalid_records = validator.clean_years(strategy='remove')\n",
    "# \n",
    "# # Or attempt corrections first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c20f5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum()>0:\n",
    "        print(missing_values[missing_values>0])\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "check_missing_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26cbaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tool Name', 'Category', 'Primary Function', 'Description', 'Website',\n",
       "       'Pricing Model', 'Key Features', 'Target Users', 'Launch Year',\n",
       "       'Company', 'category_rank', 'ID', 'Category_code', 'average_rating',\n",
       "       'review_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2a4d5",
   "metadata": {},
   "source": [
    "## Validate numeric columns: average_rating bounds  review_count non-negativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ed3162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:52,024 - INFO - Invalid ratings: 0\n",
      "2026-02-12 23:55:52,028 - INFO - Invalid review counts: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:52,093 - INFO - Cleaned 0 records with invalid numeric values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'invalid_ratings': 0, 'invalid_reviews': 0, 'total_rows': 53401}\n"
     ]
    }
   ],
   "source": [
    "class NumericValidator:\n",
    "    def __init__(self, df, rating_col='average_rating', review_col='review_count', \n",
    "                 rating_min=0, rating_max=5):\n",
    "        self.df = df.copy()\n",
    "        self.rating_col = rating_col\n",
    "        self.review_col = review_col\n",
    "        self.rating_min = rating_min\n",
    "        self.rating_max = rating_max\n",
    "        \n",
    "    def validate_ratings(self):\n",
    "        \"\"\"Check if ratings are within valid bounds\"\"\"\n",
    "        ratings = self.df[self.rating_col].copy()\n",
    "        mask = (ratings < self.rating_min) | (ratings > self.rating_max)\n",
    "        return self.df[mask & ratings.notna()]\n",
    "    \n",
    "    def validate_reviews(self):\n",
    "        \"\"\"Check if review counts are non-negative integers\"\"\"\n",
    "        reviews = self.df[self.review_col].copy()\n",
    "        \n",
    "        # Check for negative or non-integer values\n",
    "        mask_negative = reviews < 0\n",
    "        mask_non_integer = reviews != reviews.astype(int)\n",
    "        mask = (mask_negative | mask_non_integer) & reviews.notna()\n",
    "        \n",
    "        return self.df[mask]\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get validation summary\"\"\"\n",
    "        invalid_ratings = len(self.validate_ratings())\n",
    "        invalid_reviews = len(self.validate_reviews())\n",
    "        \n",
    "        summary = {\n",
    "            'invalid_ratings': invalid_ratings,\n",
    "            'invalid_reviews': invalid_reviews,\n",
    "            'total_rows': len(self.df)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Invalid ratings: {invalid_ratings}\")\n",
    "        logger.info(f\"Invalid review counts: {invalid_reviews}\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def flag_records(self):\n",
    "        \"\"\"Add flag columns for invalid values\"\"\"\n",
    "        flagged = self.df.copy()\n",
    "        \n",
    "        ratings = flagged[self.rating_col]\n",
    "        reviews = flagged[self.review_col]\n",
    "        \n",
    "        flagged['invalid_rating'] = ((ratings < self.rating_min) | (ratings > self.rating_max)) & ratings.notna()\n",
    "        flagged['invalid_review'] = ((reviews < 0) | (reviews != reviews.astype(int))) & reviews.notna()\n",
    "        \n",
    "        return flagged\n",
    "    \n",
    "    def clean_records(self, strategy='remove'):\n",
    "        \"\"\"\n",
    "        Clean invalid records\n",
    "        strategy: 'remove' (delete rows) or 'nullify' (set to NaN)\n",
    "        \"\"\"\n",
    "        invalid_ratings = self.validate_ratings()\n",
    "        invalid_reviews = self.validate_reviews()\n",
    "        invalid_indices = invalid_ratings.index.union(invalid_reviews.index)\n",
    "        \n",
    "        if strategy == 'remove':\n",
    "            cleaned = self.df[~self.df.index.isin(invalid_indices)]\n",
    "            invalid = self.df[self.df.index.isin(invalid_indices)]\n",
    "        elif strategy == 'nullify':\n",
    "            cleaned = self.df.copy()\n",
    "            \n",
    "            ratings = cleaned[self.rating_col]\n",
    "            mask_rating = ((ratings < self.rating_min) | (ratings > self.rating_max)) & ratings.notna()\n",
    "            cleaned.loc[mask_rating, self.rating_col] = np.nan\n",
    "            \n",
    "            reviews = cleaned[self.review_col]\n",
    "            mask_review = ((reviews < 0) | (reviews != reviews.astype(int))) & reviews.notna()\n",
    "            cleaned.loc[mask_review, self.review_col] = np.nan\n",
    "            \n",
    "            invalid = self.df[self.df.index.isin(invalid_indices)]\n",
    "        else:\n",
    "            raise ValueError(\"strategy must be 'remove' or 'nullify'\")\n",
    "        \n",
    "        logger.info(f\"Cleaned {len(invalid)} records with invalid numeric values\")\n",
    "        return cleaned.reset_index(drop=True), invalid\n",
    "\n",
    "\n",
    "validator = NumericValidator(cleaned_df, rating_min=0, rating_max=5)\n",
    "print(validator.get_summary())\n",
    "flagged_df = validator.flag_records()\n",
    "# # or\n",
    "cleaned_df, invalid = validator.clean_records(strategy='nullify')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e01d73",
   "metadata": {},
   "source": [
    "## Normalize text fields: Casing  Whitespace  Encoding issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da268449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:53,255 - INFO - Standardized 9 text columns\n"
     ]
    }
   ],
   "source": [
    "class TextStandardizer:\n",
    "    def __init__(self, df, text_columns=None):\n",
    "        self.df = df.copy()\n",
    "        self.text_columns = text_columns or self.df.select_dtypes(include=['object']).columns.tolist()\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Standardize single text value\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Strip leading/trailing whitespace\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Normalize unicode characters\n",
    "        text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def standardize_all(self, case_rules=None):\n",
    "        \"\"\"\n",
    "        Standardize all text columns\n",
    "        case_rules: dict mapping column names to case types\n",
    "        \"\"\"\n",
    "        standardized = self.df.copy()\n",
    "        \n",
    "        # Default case rules\n",
    "        if case_rules is None:\n",
    "            case_rules = {\n",
    "                'Tool Name': 'title',\n",
    "                'Category': 'title',\n",
    "                'Company': 'title',\n",
    "                'Primary Function': 'sentence',\n",
    "                'Description': 'sentence',\n",
    "                'Pricing Model': 'title',\n",
    "                'Target Users': 'title'\n",
    "            }\n",
    "        \n",
    "        # Clean whitespace and encoding for all text columns\n",
    "        for col in self.text_columns:\n",
    "            if col in standardized.columns:\n",
    "                standardized[col] = standardized[col].apply(self.clean_text)\n",
    "        \n",
    "        # Apply case rules\n",
    "        for col, case_type in case_rules.items():\n",
    "            if col in standardized.columns:\n",
    "                if case_type == 'title':\n",
    "                    standardized[col] = standardized[col].str.title()\n",
    "                elif case_type == 'lower':\n",
    "                    standardized[col] = standardized[col].str.lower()\n",
    "                elif case_type == 'upper':\n",
    "                    standardized[col] = standardized[col].str.upper()\n",
    "                elif case_type == 'sentence':\n",
    "                    standardized[col] = standardized[col].apply(\n",
    "                        lambda x: x.capitalize() if isinstance(x, str) else x\n",
    "                    )\n",
    "        \n",
    "        logger.info(f\"Standardized {len(self.text_columns)} text columns\")\n",
    "        return standardized\n",
    "    \n",
    "    def get_changes_summary(self, standardized_df):\n",
    "        \"\"\"Compare original vs standardized data\"\"\"\n",
    "        changes = []\n",
    "        \n",
    "        for col in self.text_columns:\n",
    "            if col in self.df.columns:\n",
    "                mask = self.df[col] != standardized_df[col]\n",
    "                changed_count = mask.sum()\n",
    "                if changed_count > 0:\n",
    "                    changes.append({\n",
    "                        'column': col,\n",
    "                        'changes': changed_count,\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(changes)\n",
    "\n",
    "# Usage:\n",
    "standardizer = TextStandardizer(cleaned_df)\n",
    "cleaned_df = standardizer.standardize_all()\n",
    "# \n",
    "# \n",
    "# # See what changed\n",
    "changes = standardizer.get_changes_summary(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98058c",
   "metadata": {},
   "source": [
    "## Flag descriptions that are too short or non-informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6f8e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:55:53,668 - INFO - Flagged 10463 invalid descriptions\n",
      "2026-02-12 23:55:53,828 - INFO - Total flagged: 10463\n",
      "2026-02-12 23:55:53,856 - INFO - \n",
      "desc_flag\n",
      "meaningless    10462\n",
      "few_words          1\n",
      "Name: count, dtype: int64\n",
      "2026-02-12 23:55:54,348 - INFO - Flagged 10463 invalid descriptions\n"
     ]
    }
   ],
   "source": [
    "class DescriptionValidator:\n",
    "    def __init__(self, df, description_col='Description', min_length=10, min_words=3):\n",
    "        self.df = df.copy()\n",
    "        self.description_col = description_col\n",
    "        self.min_length = min_length\n",
    "        self.min_words = min_words\n",
    "        self.meaningless = ['n/a', 'na', 'none', 'null', 'tbd', 'tba', 'coming soon',\n",
    "                           'no description', 'not available', 'see website', 'lorem ipsum']\n",
    "        \n",
    "    def get_flag_reason(self, text):\n",
    "        \"\"\"Check description and return reason if invalid\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return 'missing'\n",
    "        \n",
    "        text_str = str(text).strip()\n",
    "        text_lower = text_str.lower()\n",
    "        reasons = []\n",
    "        \n",
    "        if len(text_str) < self.min_length:\n",
    "            reasons.append('too_short')\n",
    "        if len(text_str.split()) < self.min_words:\n",
    "            reasons.append('few_words')\n",
    "        if any(pattern in text_lower for pattern in self.meaningless):\n",
    "            reasons.append('meaningless')\n",
    "        \n",
    "        return ', '.join(reasons) if reasons else None\n",
    "    \n",
    "    def flag_descriptions(self):\n",
    "        \"\"\"Add flag column for invalid descriptions\"\"\"\n",
    "        flagged = self.df.copy()\n",
    "        flagged['desc_flag'] = flagged[self.description_col].apply(self.get_flag_reason)\n",
    "        \n",
    "        invalid_count = flagged['desc_flag'].notna().sum()\n",
    "        logger.info(f\"Flagged {invalid_count} invalid descriptions\")\n",
    "        \n",
    "        return flagged\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get summary of flagged descriptions\"\"\"\n",
    "        flagged = self.flag_descriptions()\n",
    "        total_flagged = flagged['desc_flag'].notna().sum()\n",
    "        \n",
    "        reasons = flagged['desc_flag'].dropna().str.split(', ').explode().value_counts()\n",
    "        \n",
    "        logger.info(f\"Total flagged: {total_flagged}\")\n",
    "        logger.info(f\"\\n{reasons}\")\n",
    "        \n",
    "        return reasons\n",
    "\n",
    "# Usage:\n",
    "validator = DescriptionValidator(cleaned_df, min_length=10, min_words=3)\n",
    "summary = validator.get_summary()\n",
    "flagged_df = validator.flag_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ec2d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 23:56:17,624 - INFO - Cleaned data saved successfully\n"
     ]
    }
   ],
   "source": [
    "def save_cleaned_data(data: pd.DataFrame, filename: str, index: bool = False):\n",
    "    try: \n",
    "        data.to_csv(filename, index = False)\n",
    "        logger.info(\n",
    "            \"Cleaned data saved successfully\")\n",
    "    except IOError as e:\n",
    "        logger.error(\n",
    "            f\"Failed to save cleaned data to {filename}\",\n",
    "            exc_info=True\n",
    "        )\n",
    "\n",
    "save_cleaned_data(cleaned_df, filename=\"Cleaned_AI_Tools_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "843c7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = r\"C:\\Users\\owner\\Desktop\\Files_Deep_Learning\\NeuraGuide\\Cleaned_AI_Tools.csv\"\n",
    "# dff = load_data(path=paths)\n",
    "\n",
    "# dff.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
