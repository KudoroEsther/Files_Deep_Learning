{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057bd4cf",
   "metadata": {},
   "source": [
    "# RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfb668",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cd7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n",
      "libraries successfully imported!\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing libraries...\")\n",
    "#loading and chunking libraries\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# vector storage\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#LECL librarie\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Conversational memory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_classic.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "print(\"libraries successfully imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c01bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"paid_api\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"API key loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3534112",
   "metadata": {},
   "source": [
    "## Loading and chunking documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f7ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\owner\\Desktop\\Files_Deep_Learning\\RAG\\Project\\documents\"\n",
    "\n",
    "# Loading document\n",
    "documents = []\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        loader = TextLoader(os.path.join(data_path, file), encoding='utf-8')\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "#Chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap = 50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc56d9e",
   "metadata": {},
   "source": [
    "## Storing embeddings in a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80375bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created and saved to chroma_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owner\\AppData\\Local\\Temp\\ipykernel_8464\\3192814298.py:6: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Creating embeddings and storing\n",
    "embedding = OpenAIEmbeddings(model= \"text-embedding-3-small\", openai_api_key=api_key)\n",
    "vectorstore = Chroma.from_documents(documents=chunks,\n",
    "                                    embedding=embedding, persist_directory = \"./chroma_db\")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(f\"Embeddings created and saved to chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c563b90",
   "metadata": {},
   "source": [
    "## RAG Chain with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a9dac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0,openai_api_key=api_key)\n",
    "\n",
    "# Retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "system_prompt_text = \"\"\"\n",
    "You are a personal RAG assistant answering questions strictly from the provided context about Esther Kudoro.\n",
    "\n",
    "### INSTRUCTIONS:\n",
    "1. Answer questions about professional experience, skills, repositories, and technical implementation details.\n",
    "2. Use ONLY the context below. If the answer is not present, say \"I do not have that information.\"\n",
    "3. ALWAYS cite your sources implicitly by referring to the specific file or section.\n",
    "4. Format all responses as clean plain text with no markdown or special characters.\n",
    "\n",
    "### PRIVACY GUARDRAILS (CRITICAL):\n",
    "You MUST REFUSE to answer questions about the following personal sensitive information, even if it might be present in the context:\n",
    "- Age\n",
    "- Date of birth\n",
    "- Home Address\n",
    "- Phone number\n",
    "- Personal Email address\n",
    "- Any other sensitive personal identifiers\n",
    "\n",
    "If a user asks for this information, reply EXACTLY with:\n",
    "\"I cannot share personal or sensitive information such as contact details or age. Please ask about her professional experience or projects.\"\n",
    "\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer clearly and concisely.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt_text),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0e5b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chain created!\n"
     ]
    }
   ],
   "source": [
    "# RAG CHAIN\n",
    "from operator import itemgetter\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\")\n",
    "        | retriever\n",
    "        | format_docs,\n",
    "\n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG Chain created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e289ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esther Kudoro Personal Assistant \n",
      "Type either 'exit' or 'quit' to stop the program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I do not have that information.\n",
      "\n",
      "Assistant: I do not have that information.\n",
      "\n",
      "Assistant: Esther Kudoro is an Electrical and Electronics Engineer with first-class honors from Afe Babalola University, where she was recognized as the Best Graduating Student in Power Systems Engineering. She has a strong interest in power systems engineering, data analytics, and machine learning, focusing on applying artificial intelligence and data-driven techniques to engineering problems. Her professional interests include fault diagnosis, predictive maintenance, and retrieval-augmented generation systems. Esther has technical skills in electrical and electronics engineering, power systems engineering, electrical fault analysis, and data and machine learning, including data analysis, feature engineering, and classification models. She has experience with Python for data science and machine learning tasks. Additionally, she has participated in professional and virtual internship programs, such as the RadicalX Tech Global Virtual Internship and the UK Internship Experience program, which helped her develop practical skills and industry awareness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "print(\"Esther Kudoro Personal Assistant \\nType either 'exit' or 'quit' to stop the program.\")\n",
    "\n",
    "while True:\n",
    "    question = input(\"You: \")\n",
    "    if question.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    answer = rag_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "\n",
    "    print(f\"Assistant: {answer}\\n\")\n",
    "\n",
    "    chat_history.extend([\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=answer)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd943209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "# You are a personal RAG assistant answering questions strictly\n",
    "# from the provided context about Esther Kudoro.\n",
    "\n",
    "# Use ONLY the context below.\n",
    "# If the answer is not present, say \"I do not have that information.\"\n",
    "\n",
    "# Context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "\n",
    "# Answer clearly and concisely.\n",
    "# Always include source references.\n",
    "# \"\"\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "# retriever = vectorstore.as_retriever(search_kwargs={\"k\":4})\n",
    "\n",
    "# rag_chain = (\n",
    "#     {\n",
    "#         \"context\": retriever,\n",
    "#         \"question\": RunnablePassthrough()\n",
    "#     }\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     |StrOutputParser()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be989a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a personal RAG assistant answering questions strictly\n",
    "from the provided context about Esther Kudoro.\n",
    "Use ONLY the context below.\n",
    "If the answer is not present, say \"I do not have that information.\"\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Chat History: {chat_history}\n",
    "\n",
    "Question: {question}\n",
    "Answer clearly and concisely.\n",
    "Always include source references.\n",
    "\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, openai_api_key=api_key)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Helper function to format chat history\n",
    "def format_chat_history(messages):\n",
    "    if not messages:\n",
    "        return \"\"\n",
    "    formatted = []\n",
    "    for msg in messages:\n",
    "        role = \"Human\" if msg.type == \"human\" else \"Assistant\"\n",
    "        formatted.append(f\"{role}: {msg.content}\")\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: format_chat_history(x.get(\"chat_history\", []))\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a2977",
   "metadata": {},
   "source": [
    "## Initialising and activating conversational memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be1d5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "rag_chain_with_memory = RunnableWithMessageHistory(\n",
    "    rag_chain, get_session_history, \n",
    "    input_messages_key = \"question\",\n",
    "    history_messages_key= \"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb43dcc",
   "metadata": {},
   "source": [
    "## Running the RAG assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc64a8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'text': 'dict' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m question.lower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m answer = \u001b[43mrag_chain_with_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msession_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mesther-session\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAssitant: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4739\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4735\u001b[39m         msg = (\n\u001b[32m   4736\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit reached when invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4737\u001b[39m         )\n\u001b[32m   4738\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m4739\u001b[39m     output = \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4740\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4742\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4743\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4744\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrecursion_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecursion_limit\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4745\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4746\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4747\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3141\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3139\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3141\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3142\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3143\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3868\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3862\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3863\u001b[39m         futures = [\n\u001b[32m   3864\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3865\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3866\u001b[39m         ]\n\u001b[32m   3867\u001b[39m         output = {\n\u001b[32m-> \u001b[39m\u001b[32m3868\u001b[39m             key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3869\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3870\u001b[39m         }\n\u001b[32m   3871\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3872\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3851\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3845\u001b[39m child_config = patch_config(\n\u001b[32m   3846\u001b[39m     config,\n\u001b[32m   3847\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3848\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3849\u001b[39m )\n\u001b[32m   3850\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3851\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3853\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3855\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\retrievers.py:216\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    220\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1040\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1038\u001b[39m kwargs_ = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1042\u001b[39m     docs_and_similarities = (\n\u001b[32m   1043\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1044\u001b[39m             query, **kwargs_\n\u001b[32m   1045\u001b[39m         )\n\u001b[32m   1046\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:350\u001b[39m, in \u001b[36mChroma.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    334\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    335\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    338\u001b[39m     **kwargs: Any,\n\u001b[32m    339\u001b[39m ) -> List[Document]:\n\u001b[32m    340\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[32m    341\u001b[39m \n\u001b[32m    342\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m \u001b[33;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[32m    349\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:439\u001b[39m, in \u001b[36mChroma.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, where_document, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.__query_collection(\n\u001b[32m    432\u001b[39m         query_texts=[query],\n\u001b[32m    433\u001b[39m         n_results=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    436\u001b[39m         **kwargs,\n\u001b[32m    437\u001b[39m     )\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     query_embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.__query_collection(\n\u001b[32m    441\u001b[39m         query_embeddings=[query_embedding],\n\u001b[32m    442\u001b[39m         n_results=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m         **kwargs,\n\u001b[32m    446\u001b[39m     )\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:759\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_query\u001b[39m\u001b[34m(self, text, **kwargs)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[32m    750\u001b[39m \n\u001b[32m    751\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    756\u001b[39m \u001b[33;03m    Embedding for the text.\u001b[39;00m\n\u001b[32m    757\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    758\u001b[39m \u001b[38;5;28mself\u001b[39m._ensure_sync_client_available()\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:709\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;66;03m# Unconditionally call _get_len_safe_embeddings to handle length safety.\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[38;5;66;03m# This could be optimized to avoid double work when all texts are short enough.\u001b[39;00m\n\u001b[32m    708\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:553\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    551\u001b[39m _chunk_size = chunk_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_size\n\u001b[32m    552\u001b[39m client_kwargs = {**\u001b[38;5;28mself\u001b[39m._invocation_params, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m _iter, tokens, indices, token_counts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Process in batches respecting the token limit\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:508\u001b[39m, in \u001b[36mOpenAIEmbeddings._tokenize\u001b[39m\u001b[34m(self, texts, chunk_size)\u001b[39m\n\u001b[32m    506\u001b[39m     token = encoding.encode(text, **encoder_kwargs)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     token = \u001b[43mencoding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_ordinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[38;5;66;03m# Split tokens into chunks respecting the embedding_ctx_length\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(token), \u001b[38;5;28mself\u001b[39m.embedding_ctx_length):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\tiktoken\\core.py:73\u001b[39m, in \u001b[36mEncoding.encode_ordinary\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Encodes a string into tokens, ignoring special tokens.\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[33;03mThis is equivalent to `encode(text, disallowed_special=())` (but slightly faster).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m[31373, 995]\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_core_bpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_ordinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# See comment in encode\u001b[39;00m\n\u001b[32m     76\u001b[39m     text = text.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m\"\u001b[39m).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: argument 'text': 'dict' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"You: \")\n",
    "    if question.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    answer = rag_chain_with_memory.invoke(\n",
    "        {\"question\":question},\n",
    "        config={\"configurable\": {\"session_id\": \"esther-session\"}}\n",
    "    )\n",
    "\n",
    "    print(f\"\\nAssitant: {answer} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
