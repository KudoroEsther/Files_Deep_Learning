{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dec7052",
   "metadata": {},
   "source": [
    "## FAISS Vector Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a76b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"FAISS version: {faiss.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227b8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"Python is a versatile programming language used for web development and data science.\",\n",
    "    \"Machine learning models require large amounts of training data to perform well.\",\n",
    "    \"Neural networks are inspired by the structure of the human brain.\",\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Deep learning is a subset of machine learning using multi-layered neural networks.\",\n",
    "    \"Data visualization helps communicate insights from complex datasets.\",\n",
    "    \"Cloud computing provides on-demand access to computing resources.\",\n",
    "    \"Cybersecurity protects systems and networks from digital attacks.\",\n",
    "    \"Blockchain technology enables secure, decentralized transactions.\",\n",
    "    \"Quantum computing uses quantum mechanics to solve complex problems.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8744e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 embeddings\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be8ee5",
   "metadata": {},
   "source": [
    "### FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45e6dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors in index: 10\n"
     ]
    }
   ],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "#Create FAISS index (IndexFlatL2 = exact search with L2 distance)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "index.add(embeddings)\n",
    "print(f\"Total vectors in index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e61b0",
   "metadata": {},
   "source": [
    "### Search with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8c9ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence and machine learning?\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Distance: 0.9079)\n",
      "    Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "\n",
      "2. (Distance: 1.2202)\n",
      "    Machine learning models require large amounts of training data to perform well.\n",
      "\n",
      "3. (Distance: 1.2355)\n",
      "    Natural language processing enables computers to understand human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is artificial intelligence and machine learning?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "k=3\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Top {k} results:\\n\")\n",
    "\n",
    "for i, (idx, distance) in enumerate(zip(indices[0], distances[0]),1):\n",
    "    print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    print(f\"    {documents[idx]}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862da3a",
   "metadata": {},
   "source": [
    "### Using Cosine Similarity with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec39a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence and machine learning?\n",
      "\n",
      "Top 3 results with cosine similarity:\n",
      "\n",
      "1. (Similarity: 0.5460)\n",
      "   Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "\n",
      "2. (Similarity: 0.3899)\n",
      "   Machine learning models require large amounts of training data to perform well.\n",
      "\n",
      "3. (Similarity: 0.3823)\n",
      "   Natural language processing enables computers to understand human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize embeddings for cosine similarity\n",
    "embeddings_normalized = embeddings/np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Create index with inner product (equivalent to cosine for normalized vectors)\n",
    "index_cosine = faiss.IndexFlatIP(dimension)\n",
    "index_cosine.add(embeddings_normalized)\n",
    "\n",
    "#Search with normalized query\n",
    "query_embedding_normalized = query_embedding/np.linalg.norm(query_embedding)\n",
    "scores, indices = index_cosine.search(query_embedding_normalized, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Top {k} results with cosine similarity:\\n\")\n",
    "\n",
    "for i, (idx, score) in enumerate(zip(indices[0], scores[0]), 1):\n",
    "    print(f\"{i}. (Similarity: {score:.4f})\")\n",
    "    print(f\"   {documents[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568ae07",
   "metadata": {},
   "source": [
    "### Saving and Loading FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df366ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved to disk\n",
      "Documents saved\n"
     ]
    }
   ],
   "source": [
    "#Save index to disk\n",
    "faiss.write_index(index_cosine, \"my_faiss_index.bin\")\n",
    "print(\"Index saved to disk\")\n",
    "\n",
    "# Save documents separately (FAISS only stores vectors not text)\n",
    "import pickle\n",
    "with open(\"documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents, f)\n",
    "print(\"Documents saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d306318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index loaded: 10 vectors\n",
      "Documents loaded: 10 documents\n"
     ]
    }
   ],
   "source": [
    "# Load index from disk\n",
    "loaded_index = faiss.read_index(\"my_faiss_index.bin\")\n",
    "print(f\"Index loaded: {loaded_index.ntotal} vectors\")\n",
    "\n",
    "# Load documents \n",
    "with open(\"documents.pkl\", \"rb\") as f:\n",
    "    loaded_documents = pickle.load(f)\n",
    "print(f\"Documents loaded: {len(loaded_documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f5df2",
   "metadata": {},
   "source": [
    "## Chroma Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867e0328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromadb version: 1.3.7\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "print(f\"Chromadb version: {chromadb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c80f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_documents\n",
      "Current count: 0 documents\n"
     ]
    }
   ],
   "source": [
    "#Create Chroma client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"my_documents\",\n",
    "    metadata={\"description\": \"Sample document collection\"}\n",
    "\n",
    ")\n",
    "print(collection.name)\n",
    "print(f\"Current count: {collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973a6cf",
   "metadata": {},
   "source": [
    "### Add Documents to Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473978ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owner\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz:  27%|██▋       | 21.7M/79.3M [06:54<44:06, 22.8kiB/s]  "
     ]
    }
   ],
   "source": [
    "\n",
    "documents = [\n",
    "    \"Python is a versatile programming language used for web development and data science.\",\n",
    "    \"Machine learning models require large amounts of training data to perform well.\",\n",
    "    \"Neural networks are inspired by the structure of the human brain.\",\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Deep learning is a subset of machine learning using multi-layered neural networks.\"\n",
    "]\n",
    "\n",
    "# metadata for each document\n",
    "metadatas = [\n",
    "    {\"category\": \"programming\", \"topic\": \"python\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"machine learning\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"neural networks\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"NLP\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"deep learning\"}\n",
    "]\n",
    "\n",
    "#IDs for each document\n",
    "ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "# Add to collection (Chroma handles embedding automatically!)\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids = ids\n",
    ")\n",
    "\n",
    "print(f\"Total documents: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed191e7",
   "metadata": {},
   "source": [
    "### Query Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts = ['What is artificial intelligence?'],\n",
    "    n_results =3\n",
    ")\n",
    "\n",
    "print(\"Query: What is artificial intelligence?\\n\")\n",
    "print(\"Top 3 results:\\n\")\n",
    "\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0], # we used [0] to extract the response for the first query because chromadb gives its response as a list of list, in order to be able to isolate the response for \n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    ",\n",
    "), 1):\n",
    "    print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "    print(f\"   Metadata: {metadata}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
