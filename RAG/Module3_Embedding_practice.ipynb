{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a422a0",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8eebbd",
   "metadata": {},
   "source": [
    "## Generating an initial embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a947d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dd8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\owner\\Desktop\\Files_Deep_Learning\\a_deep\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a85c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model produces 384 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "# Load an embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(f\"Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5f62c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (384,)\n",
      "\n",
      "First 10 embedding values:\n",
      "[ 0.13040186 -0.01187012 -0.02811704  0.05123863 -0.05597441  0.03019154\n",
      "  0.03016129  0.02469839 -0.01837056  0.05876678]\n"
     ]
    }
   ],
   "source": [
    "# Generating embedding\n",
    "text = \"The cat sat on the mat\"\n",
    "\n",
    "embedding = model.encode(text)\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"\\nFirst 10 embedding values:\\n{embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf234a",
   "metadata": {},
   "source": [
    "## Similarity: The Heart of RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3180314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity function ready\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product/ (norm1 * norm2)\n",
    "print(\"Similarity function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f0021",
   "metadata": {},
   "source": [
    "### Testing Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ccf2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing to: 'The cat sat on the mat'\n",
      "\n",
      "Similarity to 'The cat sat on the mat'\n",
      "Score: 1.000\n",
      "\n",
      "Similarity to 'A feline rested on the rug'\n",
      "Score: 0.564\n",
      "\n",
      "Similarity to 'Dogs are loyal animals'\n",
      "Score: 0.165\n",
      "\n",
      "Similarity to 'Python is a programming language'\n",
      "Score: 0.031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test sentences\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A feline rested on the rug\",      # Similar meaning, different words\n",
    "    \"Dogs are loyal animals\",          # Different topic\n",
    "    \"Python is a programming language\" # Completely unrelated\n",
    "]\n",
    "\n",
    "# Generate embedding for all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compare the first sentence to all others\n",
    "print(\"Comparing to: 'The cat sat on the mat'\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"Similarity to '{sentence}'\")\n",
    "    print(f\"Score: {similarity:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f1031",
   "metadata": {},
   "source": [
    "## Building a Simple Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924b1f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base: 8 documents\n"
     ]
    }
   ],
   "source": [
    "# Sample knowledge base\n",
    "documents = [\n",
    "    \"Python is a high-level programming language known for simplicity\",\n",
    "    \"Machine learning enables computers to learn from data\",\n",
    "    \"Neural networks are inspired by biological brains\",\n",
    "    \"Dogs are loyal and friendly pets that need exercise\",\n",
    "    \"Cats are independent animals that make great companions\",\n",
    "    \"JavaScript is used for web development and runs in browsers\",\n",
    "    \"Deep learning uses multi-layered neural networks\",\n",
    "    \"Puppies require training and socialization from an early age\"\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base: {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98b7a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for all documents...\n",
      "✅ Created 8 embeddings\n",
      "Each embedding has 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all documents\n",
    "print(\"Generating embeddings for all documents...\")\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"✅ Created {len(doc_embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {doc_embeddings[0].shape[0]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea0a1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function\n",
    "def search(query, documents, doc_embeddings, top_k=3):\n",
    "    \"\"\"\n",
    "    Search for documents similar to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query (string)\n",
    "        documents: List of document texts\n",
    "        doc_embeddings: Pre-computed document embeddings\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (document, similarity_score) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarities=[]\n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((documents[i], similarity))\n",
    "\n",
    "    # Sort by similarity (highest first)\n",
    "    similarities.sort(key=lambda x:x[i], reverse=True)\n",
    "\n",
    "    # Return top k results\n",
    "    return similarities[: top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99a0c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY: What is artificial intelligence?\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQUERY: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m results = \u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (doc, score) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results, \u001b[32m1\u001b[39m):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. (Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36msearch\u001b[39m\u001b[34m(query, documents, doc_embeddings, top_k)\u001b[39m\n\u001b[32m     23\u001b[39m     similarities.append((documents[i], similarity))\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Sort by similarity (highest first)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43msimilarities\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Return top k results\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m similarities[: top_k]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36msearch.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     23\u001b[39m     similarities.append((documents[i], similarity))\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Sort by similarity (highest first)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m similarities.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Return top k results\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m similarities[: top_k]\n",
      "\u001b[31mIndexError\u001b[39m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Test different queries\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me about pet dogs\",\n",
    "    \"How do I code in Python?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "\n",
    "    results = search(query, documents, doc_embeddings)\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. (Score: {score:3f})\")\n",
    "        print(f\" {doc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
