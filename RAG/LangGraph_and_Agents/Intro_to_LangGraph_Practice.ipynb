{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce9cd42",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph & State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f1bcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "print(\"All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a27ba90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"paid_api\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API Key not found!\")\n",
    "print(\"API Key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173a7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512b8c9",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e0c96",
   "metadata": {},
   "source": [
    "State is the data that flows through the graph<br>\n",
    "MessagesState: stores conversation history<br>\n",
    "\n",
    "Nodes processes the state and return updates, they are defined the way functions are defined<br>\n",
    "\n",
    "Edges are connections between nodes that control the flow of the agent. They include static and conditional edges, conditional edges are dynamic and enable decision making<br>\n",
    "\n",
    "Checkpointer gives the agent memory by saving the state between interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1343f873",
   "metadata": {},
   "source": [
    "### The Assistant Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48befc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant mode defined\n"
     ]
    }
   ],
   "source": [
    "# A node that send messages to the LLM and gets a response\n",
    "sys_msg = SystemMessage(\n",
    "    content= \"You are a friendly assistant that answers user question. Be helpful and concise.\"\n",
    ")\n",
    "\n",
    "def assistant(state: MessagesState) -> dict: #state expect an input in the form of MessagesState, and gives a dictionary as the output\n",
    "    \"\"\"\n",
    "    The assistant node - processes messages and generates response.\n",
    "    \"\"\"\n",
    "    #Combines system prompt with conversation history\n",
    "    messages = [sys_msg] + state[\"messages\"] #MessagesState contains a dictionary of list with messages as the key\n",
    "\n",
    "    #Get response from LLM\n",
    "    response = llm.invoke(messages)\n",
    "    #Return as state update\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "print(\"Assistant mode defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b07709",
   "metadata": {},
   "source": [
    "## Building the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "658ac725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph structure defined\n"
     ]
    }
   ],
   "source": [
    "#Create a StateGraph with MessagesState\n",
    "builder = StateGraph(MessagesState)\n",
    "#Adding teh assistant node\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "\n",
    "#Define the flow:\n",
    "# START -> assitant -> END\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "print(\"Graph structure defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a106eee",
   "metadata": {},
   "source": [
    "### Checkpointers Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a20c38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent compiled with memory\n"
     ]
    }
   ],
   "source": [
    "#Create a memory checkpointer\n",
    "memory = MemorySaver()\n",
    "\n",
    "#Compile graph with memory\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "print(\"Agent compiled with memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a36ae5",
   "metadata": {},
   "source": [
    "### Visualizing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45b6ebe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph structure: Start -> assistant -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116acd54",
   "metadata": {},
   "source": [
    "### Running the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657ce4a",
   "metadata": {},
   "source": [
    "Messages with the same session ids/ thread ids share memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "564784f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversation with session ID: chat_session_0012\n"
     ]
    }
   ],
   "source": [
    "# Defining a session id for the conversation\n",
    "session_id = \"chat_session_0012\"\n",
    "print(f\"Starting conversation with session ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b11be",
   "metadata": {},
   "source": [
    "#### Helper function for Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a10376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation function ready\n"
     ]
    }
   ],
   "source": [
    "def run_conversation(user_input: str, thread_id: str=session_id):\n",
    "    \"\"\"\n",
    "    Send a message to the agent and get response.\n",
    "    WARNING: Using default thread_id shares conversation acrosss all calls!\n",
    "    In production, ALWAYS provide unique thread_id per user.\n",
    "    \"\"\"\n",
    "    #Invoke the agent\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "\n",
    "    # Print the conversation\n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"\\n User: {message.content}\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            print(f\"Agent: {message.content}\")\n",
    "    print(\"\\n\"+ \"=\"*70)\n",
    "\n",
    "print(\"Conversation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c196033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: Hello! What is your name?\n",
      "Agent: Hello! I don't have a specific name, but you can call me Assistant. How can I help you today?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"Hello! What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58959b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: Hello! What is your name?\n",
      "Agent: Hello! I don't have a specific name, but you can call me Assistant. How can I help you today?\n",
      "\n",
      " User: My favorite color is blue\n",
      "Agent: That's great! Blue is a calming and versatile color. Do you have a specific shade of blue you like best?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"My favorite color is blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91affa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: Hello! What is your name?\n",
      "Agent: Hello! I don't have a specific name, but you can call me Assistant. How can I help you today?\n",
      "\n",
      " User: My favorite color is blue\n",
      "Agent: That's great! Blue is a calming and versatile color. Do you have a specific shade of blue you like best?\n",
      "\n",
      " User: What is my favorite color?\n",
      "Agent: Your favorite color is blue!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"What is my favorite color?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a881e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: What is my favorite color?\n",
      "Agent: I don't have access to your personal preferences, so I can't determine your favorite color. However, feel free to share it if you'd like!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"What is my favorite color?\", thread_id=\"111\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86eb08",
   "metadata": {},
   "source": [
    "#### Test: Context-Dependent Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "286dcaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: Hello! What is your name?\n",
      "Agent: Hello! I don't have a specific name, but you can call me Assistant. How can I help you today?\n",
      "\n",
      " User: My favorite color is blue\n",
      "Agent: That's great! Blue is a calming and versatile color. Do you have a specific shade of blue you like best?\n",
      "\n",
      " User: What is my favorite color?\n",
      "Agent: Your favorite color is blue!\n",
      "\n",
      " User: I'm learning about RAG systems\n",
      "Agent: That's interesting! RAG systems, or Retrieval-Augmented Generation systems, combine information retrieval with generative models to improve the quality and relevance of generated responses. They typically fetch relevant documents or data from a database and then use that information to generate more accurate and contextually appropriate text. Do you have any specific questions about RAG systems?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start a new topic\n",
    "run_conversation(\"I'm learning about RAG systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da1338ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: Hello! What is your name?\n",
      "Agent: Hello! I don't have a specific name, but you can call me Assistant. How can I help you today?\n",
      "\n",
      " User: My favorite color is blue\n",
      "Agent: That's great! Blue is a calming and versatile color. Do you have a specific shade of blue you like best?\n",
      "\n",
      " User: What is my favorite color?\n",
      "Agent: Your favorite color is blue!\n",
      "\n",
      " User: I'm learning about RAG systems\n",
      "Agent: That's interesting! RAG systems, or Retrieval-Augmented Generation systems, combine information retrieval with generative models to improve the quality and relevance of generated responses. They typically fetch relevant documents or data from a database and then use that information to generate more accurate and contextually appropriate text. Do you have any specific questions about RAG systems?\n",
      "\n",
      " User: Can you explain the main components?\n",
      "Agent: Certainly! The main components of a Retrieval-Augmented Generation (RAG) system typically include:\n",
      "\n",
      "1. **Retriever**: This component is responsible for searching and retrieving relevant documents or pieces of information from a knowledge base or database. It uses techniques like vector similarity or keyword matching to find the most pertinent data related to a user's query.\n",
      "\n",
      "2. **Generator**: After the retriever has fetched relevant information, the generator takes this data and uses it to create a coherent and contextually relevant response. This is often based on a generative language model, which can produce human-like text.\n",
      "\n",
      "3. **Knowledge Base**: This is the collection of documents or data from which the retriever pulls information. It can include structured data (like databases) and unstructured data (like articles or web pages).\n",
      "\n",
      "4. **Fusion Mechanism**: Some RAG systems include a fusion mechanism that integrates the retrieved information with the input query to produce a more informed response. This can involve techniques like attention mechanisms to weigh the importance of different pieces of retrieved data.\n",
      "\n",
      "5. **Evaluation Component**: This component assesses the relevance and quality of the generated responses, often using metrics or human feedback to improve the system's performance over time.\n",
      "\n",
      "These components work together to enhance the overall capability of the system, making it more effective at answering questions and providing information. If you have more questions or need further details, feel free to ask!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"Can you explain the main components?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e836704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User: Hello! What is your name?\n",
      "Agent: Hello! I don't have a specific name, but you can call me Assistant. How can I help you today?\n",
      "\n",
      " User: My favorite color is blue\n",
      "Agent: That's great! Blue is a calming and versatile color. Do you have a specific shade of blue you like best?\n",
      "\n",
      " User: What is my favorite color?\n",
      "Agent: Your favorite color is blue!\n",
      "\n",
      " User: I'm learning about RAG systems\n",
      "Agent: That's interesting! RAG systems, or Retrieval-Augmented Generation systems, combine information retrieval with generative models to improve the quality and relevance of generated responses. They typically fetch relevant documents or data from a database and then use that information to generate more accurate and contextually appropriate text. Do you have any specific questions about RAG systems?\n",
      "\n",
      " User: Can you explain the main components?\n",
      "Agent: Certainly! The main components of a Retrieval-Augmented Generation (RAG) system typically include:\n",
      "\n",
      "1. **Retriever**: This component is responsible for searching and retrieving relevant documents or pieces of information from a knowledge base or database. It uses techniques like vector similarity or keyword matching to find the most pertinent data related to a user's query.\n",
      "\n",
      "2. **Generator**: After the retriever has fetched relevant information, the generator takes this data and uses it to create a coherent and contextually relevant response. This is often based on a generative language model, which can produce human-like text.\n",
      "\n",
      "3. **Knowledge Base**: This is the collection of documents or data from which the retriever pulls information. It can include structured data (like databases) and unstructured data (like articles or web pages).\n",
      "\n",
      "4. **Fusion Mechanism**: Some RAG systems include a fusion mechanism that integrates the retrieved information with the input query to produce a more informed response. This can involve techniques like attention mechanisms to weigh the importance of different pieces of retrieved data.\n",
      "\n",
      "5. **Evaluation Component**: This component assesses the relevance and quality of the generated responses, often using metrics or human feedback to improve the system's performance over time.\n",
      "\n",
      "These components work together to enhance the overall capability of the system, making it more effective at answering questions and providing information. If you have more questions or need further details, feel free to ask!\n",
      "\n",
      " User: Which component is most important?\n",
      "Agent: It's difficult to pinpoint one component as the most important in a RAG system, as they all work together to create effective responses. However, the **retriever** is often considered crucial because:\n",
      "\n",
      "1. **Relevance**: The quality of the retrieved information directly impacts the accuracy and relevance of the generated response. If the retriever fails to fetch pertinent documents, the generator has less useful information to work with.\n",
      "\n",
      "2. **Efficiency**: A strong retriever can quickly narrow down vast amounts of data to the most relevant pieces, which is essential for performance, especially in real-time applications.\n",
      "\n",
      "That said, the **generator** is equally important because it interprets and synthesizes the retrieved information into a coherent and natural response. Ultimately, the effectiveness of a RAG system depends on the synergy between the retriever and generator, along with the quality of the knowledge base. Each component contributes to the overall performance, so improving any single part can enhance the system's effectiveness.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"Which component is most important?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a59ec2",
   "metadata": {},
   "source": [
    "### Multiple Conversations using different thread ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5771d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”µ CONVERSATION 1\n",
      "\n",
      " User: My name is Alice\n",
      "Agent: Nice to meet you, Alice! How can I assist you today?\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ðŸŸ¢ CONVERSATION 2\n",
      "\n",
      " User: My name is Bob\n",
      "Agent: Nice to meet you, Bob! How can I assist you today?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Conversation 1\n",
    "print(\"\\nðŸ”µ CONVERSATION 1\")\n",
    "run_conversation(\"My name is Alice\", thread_id=\"user_alicee\")\n",
    "\n",
    "# Conversation 2 (different user)\n",
    "print(\"\\nðŸŸ¢ CONVERSATION 2\")\n",
    "run_conversation(\"My name is Bob\", thread_id=\"user_bobb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ab99255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”µ BACK TO CONVERSATION 1\n",
      "\n",
      " User: My name is Alice\n",
      "Agent: Nice to meet you, Alice! How can I assist you today?\n",
      "\n",
      " User: What's my name?\n",
      "Agent: Your name is Alice! How can I help you today?\n",
      "\n",
      " User: What's my name?\n",
      "Agent: Your name is Alice. How can I assist you further?\n",
      "\n",
      " User: What's my name?\n",
      "Agent: Your name is Alice. If you have any other questions or need assistance, feel free to ask!\n",
      "\n",
      " User: What's my name?\n",
      "Agent: Your name is Alice. Let me know if there's anything else you'd like to talk about!\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ðŸ”µ BACK TO CONVERSATION 1\n",
      "\n",
      " User: My name is Bob\n",
      "Agent: Nice to meet you, Bob! How can I assist you today?\n",
      "\n",
      " User: What's my name?\n",
      "Agent: Your name is Bob! How can I help you today, Bob?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Back to Alice - does it remember her name?\n",
    "print(\"\\nðŸ”µ BACK TO CONVERSATION 1\")\n",
    "run_conversation(\"What's my name?\", thread_id=\"user_alicee\")\n",
    "\n",
    "# Back to Alice - does it remember her name?\n",
    "print(\"\\nðŸ”µ BACK TO CONVERSATION 1\")\n",
    "run_conversation(\"What's my name?\", thread_id=\"user_bobb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a3b51",
   "metadata": {},
   "source": [
    "### Interactive Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4268fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"\n",
    "    Run an interactive chat session.\n",
    "    Type 'exit' or 'quit' to stop.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Interactive Chat Started\")\n",
    "    print(\"Type your message and press Enter. Type 'exit' to quit.\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    thread_id = \"interactive_session2\"\n",
    "\n",
    "    while True:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
