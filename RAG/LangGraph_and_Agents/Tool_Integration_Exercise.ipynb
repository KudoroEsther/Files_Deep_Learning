{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0154a7",
   "metadata": {},
   "source": [
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8917a1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c8f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "import re\n",
    "\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92681bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('paid_api')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found!\")\n",
    "print(\"API Key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbe2ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized gpt-40-mini\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-40-mini\",\n",
    "    temperature = 0.7,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8ee6b",
   "metadata": {},
   "source": [
    "## Creating Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@ tool\n",
    "def weather_tool(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns simulated weather for a given city.\n",
    "    Use this tool when the weather of a given city is required.\n",
    "\n",
    "    Args:\n",
    "        city: The given city\n",
    "    \n",
    "    Returns:\n",
    "        A simulated weather for the city\n",
    "    \"\"\"\n",
    "\n",
    "    def simulate_weather(city: str) ->dict:\n",
    "        \"\"\"\n",
    "        Generate deterministic fake weather data for a city.\n",
    "        \"\"\"\n",
    "        random.seed(city.lower())\n",
    "\n",
    "        conditions = [\"Sunny\", \"Cloudy\", \"Rainy\", \"Thunderstorm\", \"Hazy\"]\n",
    "        \n",
    "        return {\n",
    "            \"city\": city.title(),\n",
    "            \"temperature_c\": random.randint(22, 36),\n",
    "            \"condition\": random.choice(conditions),\n",
    "            \"humidity_percent\": random.randint(40, 90)\n",
    "        }\n",
    "    \n",
    "    weather = simulate_weather(city)\n",
    "    return (\n",
    "        f\"Weather in {weather['city']}:\\n\"\n",
    "        f\"- Temperature: {weather['temperature_c']}Â°C\\n\"\n",
    "        f\"- Condition: {weather['condition']}\\n\"\n",
    "        f\"- Humidity: {weather['humidity_percent']}%\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b224a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def dictionary(question: str) -> str:\n",
    "    pass\n",
    "    \"\"\"\n",
    "    Accepts a question and returns a definition from a simulated dictionary.\n",
    "\n",
    "    Example inputs:\n",
    "    - \"What is the meaning of agent?\"\n",
    "    - \"Define RAG\"\n",
    "    - \"What does embedding mean?\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulated dictionary\n",
    "    dictionary = {\n",
    "        \"agent\": \"An entity that perceives its environment and acts upon it.\",\n",
    "        \"tool\": \"A function or capability an agent can use to perform a task.\",\n",
    "        \"rag\": \"Retrieval-Augmented Generation, combining retrieval with generation.\",\n",
    "        \"llm\": \"Large Language Model trained on vast amounts of text data.\",\n",
    "        \"embedding\": \"A numerical representation of text capturing semantic meaning.\"\n",
    "    }\n",
    "\n",
    "    # Normalize question\n",
    "    word = question.lower().strip()\n",
    "\n",
    "\n",
    "    # Lookup\n",
    "    if word in dictionary:\n",
    "        return f\"{word.title()}: {dictionary[word]}\"\n",
    "    else:\n",
    "        return f\"{word.title()}: Definition not found in the simulated dictionary.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8401779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the web using DuckDuckGo and returns summarized results.\n",
    "\n",
    "    Example inputs:\n",
    "    - \"Latest news on AI\"\n",
    "    - \"What is LangGraph?\"\n",
    "    - \"Weather patterns in Nigeria\"\n",
    "    \"\"\"\n",
    "\n",
    "    results_text = []\n",
    "\n",
    "    with DDGS() as ddgs:\n",
    "        results = ddgs.text(\n",
    "            query,\n",
    "            region=\"wt-wt\",\n",
    "            safesearch=\"moderate\",\n",
    "            max_results=5\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            title = r.get(\"title\", \"No title\")\n",
    "            snippet = r.get(\"body\", \"No summary\")\n",
    "            source = r.get(\"href\", \"No link\")\n",
    "\n",
    "            results_text.append(\n",
    "                f\"Title: {title}\\n\"\n",
    "                f\"Summary: {snippet}\\n\"\n",
    "                f\"Source: {source}\\n\"\n",
    "            )\n",
    "\n",
    "    if not results_text:\n",
    "        return \"No results found.\"\n",
    "\n",
    "    return \"\\n---\\n\".join(results_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b3a06",
   "metadata": {},
   "source": [
    "## Binding tools to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools= [weather_tool, dictionary, web_search]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "print(f\"LLM bound to {len(tools)} tools\")\n",
    "print(f\"Tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be3418",
   "metadata": {},
   "source": [
    "## Implementing Conditional Routing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
