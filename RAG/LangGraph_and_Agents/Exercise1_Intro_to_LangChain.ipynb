{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e831190",
   "metadata": {},
   "source": [
    "# Pracitice Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "print(\"All libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = SystemMessage(\n",
    "    content = \"Your are a polite and helpful customer support rep. Answer customers' questions accurately and be concise.\"\n",
    "\n",
    ")\n",
    "\n",
    "def sales_assist(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    The assistant node - processes messages and generates response.\n",
    "    \"\"\"\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "print(\"Sales assistant mode defined\")\n",
    "\n",
    "# The graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", sales_assist)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "#Checkpointer\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent2 = builder.compile(checkpointer=memory)\n",
    "print('Agent compiled with memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"\n",
    "    Run an interactive chat session.\n",
    "    Type 'exit' or 'quit' to stop.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Interactive Chat Started\")\n",
    "    print(\"Type your message and press Enter. Type 'exit' to quit.\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    thread_id = \"interactive_session2\"\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nGoodbye...\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        #Get response\n",
    "        result = agent2.invoke(\n",
    "            {\"messages\": [HumanMessage(content=user_input)]},\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "        )\n",
    "\n",
    "        # Print response\n",
    "        agent_message = result[\"messages\"][-1]\n",
    "        user_message = result['messages'][-2]\n",
    "        print(f\"\\nYou: {user_message.content}\")\n",
    "        print(f\"\\nAgent: {agent_message.content}\")\n",
    "\n",
    "interactive_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
