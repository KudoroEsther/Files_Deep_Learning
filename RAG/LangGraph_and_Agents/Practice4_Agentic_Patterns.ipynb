{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33fe2599",
   "metadata": {},
   "source": [
    "# Agentic Patterns: ReAct, Plan-Execute, and Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1947961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ncc333\\Desktop\\Deep_Learning\\a_Deep\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal, TypedDict, Annotated\n",
    "import operator\n",
    "import os\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e73b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"paid_api\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API_Key not found. Please set it in your .env file\")\n",
    "print(\"API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cfc606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "## Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key = api_key\n",
    ")\n",
    "print(f\"LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510792c3",
   "metadata": {},
   "source": [
    "## ReAct Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2478dd3",
   "metadata": {},
   "source": [
    "## Plan-Execute Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82644c65",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized state for plan-execute\n",
    "class PlanExecuteState(TypedDict):\n",
    "    \"\"\"State for plan-execute pattern.\"\"\"\n",
    "    input: str \n",
    "    plan: list[str]\n",
    "    current_step: int\n",
    "    results: Annotated[list[str], operator.add] #Results from each step\n",
    "    final_output: str\n",
    "\n",
    "print(\"Plan-Execute state defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a13b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Planner\n",
    "def planner(state: PlanExecuteState) -> dict:\n",
    "    \"\"\"Create a step-by-step plan.\"\"\"\n",
    "    prompt = f\"\"\"Create a step-by-step plan for this task:\n",
    "\n",
    "Task: {state['input']}\n",
    "\n",
    "Return a numbered list of concrete steps. Keep it simple (3-5 steps).\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    # Parse steps (simple parsing)\n",
    "    lines = response.content.split('\\n')\n",
    "    steps = [line.strip() for line in lines if line.strip() and any(char.isdigit() for char in line[:3])]\n",
    "\n",
    "    print(lines)\n",
    "    print(f\"\\nðŸ“‹ PLAN CREATED:\")\n",
    "    for step in steps:\n",
    "        print(f\"    {step}\")\n",
    "    print()\n",
    "\n",
    "    return {\"plan\": steps, \"current_step\": 0, \"results\": []}\n",
    "\n",
    "# Node 2: Executor\n",
    "def executor(state: PlanExecuteState) -> dict:\n",
    "    \"\"\"Execute current step.\"\"\"\n",
    "    if state[\"current_step\"] >= len(state[\"plan\"]):\n",
    "        #All steps done\n",
    "        return {}\n",
    "    \n",
    "    current_step = state[\"plan\"][state[\"current_step\"]] #maps current step to a planned task\n",
    "\n",
    "    print(f\"Executing: {current_step}\")\n",
    "\n",
    "    # Execute step (simplified - just use LLM)\n",
    "    prompt = f\"\"\"Previous results: {state.get('results', [])}\\n\\nExecute this step: {current_step}\"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    result = f\"Step {state['current_step']+1} result: {response.content}\"\n",
    "    print(result)\n",
    "    print(f\"âœ“ Done\\n\")\n",
    "\n",
    "    return {\n",
    "        \"results\": [result],\n",
    "        \"current_step\": state[\"current_step\"]+1\n",
    "    }\n",
    "\n",
    "#Node Finalizer\n",
    "def finalizer(state: PlanExecuteState) -> dict:\n",
    "    \"\"\"Create final output from all results.\"\"\"\n",
    "    prompt = f\"\"\"Combine these step results into final answer:\n",
    "\n",
    "Original task: {state['input']}\n",
    "\n",
    "Results: {state['results']}\n",
    "\n",
    "Provide a clear, concise final answer.\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"final_output\": response.content}\n",
    "\n",
    "print(\"Plan-Execute nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing function\n",
    "def should_continue_execution(state: PlanExecuteState) -> Literal[\"executor\", \"finalizer\"]:\n",
    "    \"\"\"Decide if more steps to execute.\"\"\"\n",
    "    if state[\"current_step\"] < len(state[\"plan\"]):\n",
    "        return \"executor\"\n",
    "    return \"finalizer\"\n",
    "\n",
    "#Build Plan-Execute graph\n",
    "plan_execute_builder = StateGraph(PlanExecuteState)\n",
    "\n",
    "plan_execute_builder.add_node(\"planner\", planner)\n",
    "plan_execute_builder.add_node(\"executor\", executor)\n",
    "plan_execute_builder.add_node(\"finalizer\", finalizer)\n",
    "\n",
    "plan_execute_builder.add_edge(START, \"planner\")\n",
    "plan_execute_builder.add_edge(\"planner\", \"executor\")\n",
    "plan_execute_builder.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    should_continue_execution,\n",
    "    {\"executor\": \"executor\", \"finalizer\": \"finalizer\"}\n",
    ")\n",
    "plan_execute_builder.add_edge(\"finalizer\", END)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_Deep (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
