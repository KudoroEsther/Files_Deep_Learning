{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75d11d0",
   "metadata": {},
   "source": [
    "# Practice Exercise\n",
    "\n",
    "# Building my Own Agentic RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93280f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba60832",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"paid_api\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API_Key not found. Please set it in your .env file\")\n",
    "print(\"API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key = api_key\n",
    ")\n",
    "print(f\"LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16bbac",
   "metadata": {},
   "source": [
    "## Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"c:\\Users\\owner\\Downloads\\Agentic_RAG_knowledge_base\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    \n",
    "print(\"Documents loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(pages)\n",
    "print(\"Documents chunked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfa5f6",
   "metadata": {},
   "source": [
    "## Vector Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model= \"text-embeddings-3-small\",\n",
    "    api_key = api_key\n",
    ")\n",
    "print(\"Embeddings model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a34d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_path = \"./chroma_db_personal_rag\"\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"agentic_rag_docs\",\n",
    "    persist_directory=chroma_path,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "#Add documents\n",
    "vectorstore.add_documents(documents=doc_splits)\n",
    "print(f\"Vector store created with {len(doc_splits)} chunks\")\n",
    "print(f\"Persisted to: {chroma_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdde24",
   "metadata": {},
   "source": [
    "## Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006acadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for relevant documents in the knowledge base.\n",
    "    \n",
    "    Use this tool when you need information from the document collection\n",
    "    to answer the user's question. Do NOT use this for:\n",
    "    - General knowledge questions\n",
    "    - Greetings or small talk\n",
    "    - Simple calculations\n",
    "    \n",
    "    Args:\n",
    "        query: The search query describing what information is needed\n",
    "        \n",
    "    Returns:\n",
    "        Relevant document excerpts that can help answer the question\n",
    "    \"\"\"\n",
    "    # Using MMR for diverse results\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type = \"mmr\",\n",
    "        search_kwargs = {\"k\":5, \"fetch_k\":10}\n",
    "    )\n",
    "\n",
    "    results = retriever.invoke(query)\n",
    "    if not results:\n",
    "        return \"No relevant documents found\"\n",
    "    \n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Document {i+1}:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(results)\n",
    "    )\n",
    "    return formatted\n",
    "\n",
    "print(\"Retrieval tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c61c9d2",
   "metadata": {},
   "source": [
    "## Agentic RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessage(content=\"\"\"You are a helpful assistant with access to a document retrieval tool.\n",
    "\n",
    "RETRIEVAL DECISION RULES:\n",
    "\n",
    "DO NOT retrieve for:\n",
    "- Greetings: \"Hello\", \"Hi\", \"How are you\"\n",
    "- Questions about your capabilities: \"What can you help with?\", \"What do you do?\"\n",
    "- Simple math or general knowledge: \"What is 2+2?\"\n",
    "- Casual conversation: \"Thank you\", \"Goodbye\"\n",
    "\n",
    "DO retrieve for:\n",
    "- Questions asking for specific information that would be in documents\n",
    "- Requests for facts, definitions, or explanations about specialized topics\n",
    "- Any question where citing sources would improve the answer\n",
    "\n",
    "Rule of thumb: If the user is asking for information (not just chatting), retrieve first.\n",
    "\n",
    "When you retrieve documents, cite them in your answer. If documents don't contain the answer, say so.\n",
    "\"\"\")\n",
    "\n",
    "print(\"System prompt configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tool to LLM\n",
    "tools = [retrieve_documents]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to retrieve or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide whether to call tools or finish.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "print(\"Agent nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d60fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Conversation memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Agentic RAG system compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e23ef",
   "metadata": {},
   "source": [
    "## Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb50334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_agent(thread_id: str = \"default\"):\n",
    "    test_queries = [\n",
    "        \"Hi\",\n",
    "        \"What is the role of artificial intelligence in the energy industry?\",\n",
    "        \"What can you help me with?\",\n",
    "        \"What is agriculture?\",\n",
    "        \"How many grid-connected generating plants are operating in the NESI?\"\n",
    "        \"Whos is the president of Nigeria?\",\n",
    "        \"How many sectors are in the Nigerian power sector?\",\n",
    "        \"List the distribution companies (DisCos) operating in Nigeria\"\n",
    "    ]\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        result = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=query)]},\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "        )\n",
    "\n",
    "        #Check if Retrieval was used\n",
    "        used_retrieval = any(\n",
    "            isinstance(message, AIMessage) and message.tool_calls\n",
    "            for message in result[\"messages\"]\n",
    "        )\n",
    "\n",
    "        final_answer = result[\"messages\"][-1].content\n",
    "        print(f\"Agent: {final_answer}\")\n",
    "        print(f\"Decision: {'RETRIEVED' if used_retrieval else 'ANSWERED DIRECTLY'}\")\n",
    "        print(f\"\\n{'='*70}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
